\documentclass[12pt]{article}
\usepackage{amsmath, amssymb}
\usepackage{natbib}
\usepackage{geometry}
\geometry{margin=1in}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt}

\title{AI, Teamwork, and the Dynamics of Skill Formation in the Workplace}
\author{Zsófia Bárány and Miklós Koren\thanks{This version of text written by OpenAI o3 based on our model notes and deep research prompts.}}
\date{June 19, 2025}

\begin{document}
\maketitle
\section{Background and Motivation}\label{background-and-motivation}

The rapid rise of artificial intelligence (AI), especially generative
AI, is reshaping how work is organized. One notable trend is the
{replacement of entry-level roles by AI tools}. Many companies
have reportedly stopped hiring interns and junior employees, choosing
instead to rely on AI to handle tasks that junior staff used to perform.
For example, {senior lawyers now use AI to draft contracts}, and
{expert software developers leverage AI code generators (like
GitHub Copilot) to write code}, rather than delegating these tasks to
junior colleagues. Managers applaud the productivity spike --
{smaller teams delivering faster with AI assistance} -- and
question the need for juniors in such a workflow.

While this {AI-driven productivity boost} is real (field studies
show generative AI can raise worker output by 14\% on average), there is
growing concern about {long-term consequences}. If firms cut
junior positions, {who will become the next generation of experts?}
As one commentator put it, {``what happens when the seniors leave?
Who takes over their work?''}. In traditional organizations, juniors
learn from seniors via an {apprenticeship model}, gradually
acquiring the expertise to step into senior roles. AI threatens to break
this {career ladder}. The worry is that {lack of
on-the-job learning opportunities} for juniors could lead to a future
shortage of skilled seniors, and a loss of tacit knowledge that comes
from experience. Juniors also bring fresh perspectives and ``beginner's
mind'' questions that spur innovation -- benefits that may be lost if
only seasoned workers and AI are in the room.

Early evidence from labor economics supports these concerns.
{Automation appears to reduce human capital investment:} one
study finds workers whose jobs are at risk of automation are {15
percentage points less likely to participate in training} than similar
workers not exposed to automation. Firms facing automation tend to
{cut training for incumbent workers}, possibly because they
expect AI to take over tasks. In a recent IZA study, companies adopting
AI reduced continuing training for their staff, while hiring more
already-skilled workers instead. This behavior contributes to a
{``skills gap''} or polarization: fewer mid-skill workers being
developed, and a greater reliance on a small pool of high-skill experts.
On the other hand, some firms did increase {apprenticeships} even
as they adopted AI, suggesting awareness that {future workers still
need preparation for an AI-driven workplace}. These mixed findings
underscore the central trade-off: AI can raise current productivity, but
might undermine the {learning-by-doing} that builds future
productivity.

Our work develops a simple economic model to study this trade-off. We
ask: {Could the use of AI in teams lead to ``dynamic losses'' by
halting the development of human skills?} Conversely, under what
conditions can AI be integrated without depriving the next generation of
experience? We build on a framework of team production with
{senior (high-skill) and junior (low-skill) workers}, extending
it to include an AI ``worker.'' We analyze how AI affects output, wages,
and inequality in the short run, and then examine the long-run steady
state when junior workers normally learn from seniors over time. This
model helps clarify when AI is a complement that {augments
workers} versus when it becomes a substitute that {hollows out
career progression}.

In what follows, we first describe the baseline model of teams and skill
hierarchy. We then derive the equilibrium outcomes in two regimes (when
juniors are plentiful vs.~when seniors are plentiful) and discuss how
technology (communication efficiency, AI) affects productivity and wage
inequality. Next, we introduce AI as a special kind of ``free junior''
and determine when seniors would prefer AI over human juniors. Finally,
we incorporate {dynamic mentoring (learning)} into the model --
juniors can become seniors by working in teams -- and explore how the
presence of AI alters the long-run supply of skills and overall output.
Throughout, we connect our findings to recent literature. In particular,
we relate the {rent-seeking behavior and learning externalities}
in our model to the dynamic efficiency considerations highlighted by
Buera et al.~(2025), and we situate our results in the broader
discussion on AI's impact on the labor market (e.g.~Acemoglu \&
Restrepo, Korinek, etc.) with an emphasis on the potential {dynamic
losses from a lack of learning opportunities}.

\section{Model Setup: Skill Levels, Tasks, and Team
Production}\label{model-setup-skill-levels-tasks-and-team-production}

We consider an environment where problems (or tasks) have varying
difficulties. Formally, let task difficulty \(Z\) be uniformly
distributed on \([0,1]\). A worker's {skill level} \(z\) (with
\(0<z<1\)) represents the maximum difficulty of problem they can solve.
In other words, a person with skill \(z_i\) can {solve any
problem of difficulty \(Z < z_i\)} with certainty. Problems harder than
their skill level are beyond their capability. We assume there are two
classes of human workers:

{Juniors:} skill level \(z_0\) (low skill). They can solve
easier problems.

{Seniors:} skill level \(z_1\) (high skill, with
\(z_1 > z_0\)). They can solve a wider range of problems (all that
juniors can, and more).

In a {solo work} setting, if a worker devotes one unit of time to
work on random problems, their probability of solving a given problem
equals the fraction of problems within their skill range. Since
\(Z \sim U(0,1)\), a junior working alone solves a fraction \(z_0\) of
problems (those with \(Z < z_0\)), while a senior solves \(z_1\)
fraction. Thus, the {expected output per unit time} is \(z_0\)
for a junior and \(z_1\) for a senior. These values also pin down their
{solo productivity-based wage} in a competitive market: working
alone, a junior would earn \(w_0 = z_0\) per time unit, and a senior
\(w_1 = z_1\).

Now consider {teamwork:} a senior can collaborate with \(n_0\)
juniors. The idea is that juniors attempt the problems first; they will
solve the easier ones they are capable of, and {escalate the
unsolved harder problems up to the senior}. The senior then spends time
to handle those tougher problems. However, communication and
coordination take time. We assume {whenever a junior brings a
problem to the senior, the senior spends \(h < 1\) units of time on it},
whether or not the senior eventually solves it (the difficulty is
unknown until attempted). The parameter \(h\) captures the {time
cost of mentoring/communication per problem}. Importantly, \(h<1\)
reflects that it is more {time-efficient for a senior to solve a
problem brought by a junior} than to pick up a random problem on their
own. Intuitively, the junior filters and only forwards the harder subset
of problems.

Given a senior with \(n_0\) juniors under them, how do they allocate
time? Each junior works on problems for one unit of time (we normalize a
``unit of work time'' per person). In that time, each junior encounters
some problems they cannot solve (the fraction is \(1 - z_0\), since they
solve \(z_0\) fraction themselves). Those unsolved problems -- on
average \(1-z_0\) per junior -- are passed to the senior. In total, the
senior receives about \(n_0 (1 - z_0)\) problems to look at.
{Crucially, the senior must spend \(h\) time on each forwarded
problem.} Setting the senior's total time to 1 unit (one time period of
work), we get a capacity constraint: \(n_0 (1 - z_0) h \le 1.\) If the
team is working at full capacity, the senior's time is fully utilized by
handling juniors' questions. The above equation then binds, giving the
{maximum team size} a single senior can manage: 
\begin{equation}
n_0 =
\frac{1}{h(1 - z_0)}. \tag{1}
\end{equation}

This result highlights why seniors can be extremely productive when
supported by a team of juniors: if communication is efficient (small
\(h\)) and juniors only pass on the truly hard problems (small
\(1-z_0\)), a senior can leverage a large team. {The senior
essentially ``multiplies'' their expertise across \(n_0\) juniors.} In
the limit of \(h \to 0\) or \(z_0 \to 1\), the leverage goes to infinity
-- though those are extreme cases.

{Team output:} In such an optimal team, what is produced in one
unit of time? There are two sources of solved problems:

{Problems solved by juniors:} Each of the \(n_0\) juniors
  solves a fraction \(z_0\) of the problems they see. So total
  junior-solved output = \(n_0 \cdot z_0\).

{Problems solved by the senior:} The senior tackles the
forwarded problems. The senior's skill is higher, so they can solve
problems up to difficulty \(z_1\). However, note that juniors would
have solved anything below \(z_0\) already. Therefore, the senior only
{gets} problems in the difficulty range \([z_0, z_1)\) (those
below \(z_0\) solved by juniors, those above
$z_1$ unsolvable by anyone). Thus, among the problems forwarded, the fraction the senior can solve is \(\frac{z_1 - z_0}{1 - z_0}\)
(solvable out of those forwarded). Since the senior receives
\(n_0(1-z_0)\) problems (as established), the number of problems the
senior solves is:
\(n_0 (1-z_0) \times \frac{z_1 - z_0}{1 - z_0} = n_0(z_1 - z_0).\)
This simplifies nicely: {problems solved by the senior =
\(n_0 (z_1 - z_0)\).}

Adding up, the {team's total output} (problems solved by junior +
senior per senior's time) is:
\(Q_{\text{team per senior}} = n_0 z_0 + n_0 (z_1 - z_0) = n_0 z_1.\)
Using the expression for \(n_0\) from (1), this becomes: 
\begin{equation}
Q_{\text{team per senior}}  =  \frac{z_1}{h(1 - z_0)},. \tag{2}
\end{equation}
This result is striking: a senior-led team produces output
\(\frac{z_1}{h(1-z_0)}\) per senior, which can be much larger than
either a senior or junior alone. The factor \(\frac{1}{h(1-z_0)}\)
\textgreater{} 1 represents the {productivity boost from
teamwork}. It grows as communication becomes cheaper (smaller \(h\)) or
as junior skill \(z_0\) increases (meaning juniors handle a larger share
of tasks without escalation).

In fact, the marginal value of increasing the senior's skill \(z_1\) is
amplified in a team:
\(\frac{\partial Q_{\text{team}}}{\partial z_1} = \frac{1}{h(1-z_0)},\)
which is greater than 1 (since \(h(1-z_0)<1\)). By contrast, if the
senior works {solo}, the marginal return to their skill is just 1
(one more point in \(z_1\) means one more problem solved per time unit).
{Thus, a senior's skill is more valuable when complemented by a
team}. This captures the idea that high-skill individuals can have an
outsize impact when supported by others -- a phenomenon often observed
in professional firms and R\&D labs, and a key reason why {teams
leverage talent}.

We have so far treated \(n_0\) as a continuous quantity for analytical
ease. In reality \(n_0\) would be integer (number of juniors per
senior), but the formula (1) can be interpreted as a ``target'' ratio.

\subsection{Equilibrium Wages in a Static Team
Setting}\label{equilibrium-wages-in-a-static-team-setting}

We now introduce {labor market equilibrium} with a given supply
of seniors and juniors. Let \(L_1\) be the total number of seniors
(skill \(z_1\)) and \(L_0\) the number of juniors (skill \(z_0\)) in the
economy. We consider a one-period (static) scenario where each worker
either works solo or in a team. Wages \(w_1\) (for seniors) and \(w_0\)
(for juniors) will be determined by supply and demand, depending on
whether team opportunities are abundant or scarce.

Two cases naturally arise:

{Case 1: Seniors are the bottleneck (Senior-scarce, ``Too many
juniors'').} Suppose there are a lot of juniors relative to seniors,
specifically \(L_0 > n_0 L_1\). This inequality says: even if every
senior takes on a full team of \(n_0\) juniors, there would still be
some juniors left without a senior. In this scenario, {not all
juniors can join teams}; the ``excess'' juniors must work solo (since
there aren't enough seniors to mentor them). Essentially, seniors are
the limiting factor for forming teams.

In equilibrium, any junior {not} in a team will produce output on
their own and earn their solo wage \(z_0\). This sets a floor for the
junior wage: {junior wage \(w_0\) must equal \(z_0\)}, the solo
productivity. If a firm tried to pay a junior less, that junior could
instead choose to work alone and earn \(z_0\) by solving easy tasks on
their own. Thus: 
\begin{equation}
    w_0 = z_0. \tag{3}
\end{equation}

Now consider seniors. Every senior can form a team and achieve the
high output \(Q_{\text{team}} = \frac{z_1}{h(1-z_0)}\) (per time
unit). This is the {value of one senior plus \(n_0\) juniors}.
How is this value split into wages? If juniors each earn \(z_0\)
(their outside option), the total junior wage bill per team is
\(n_0 \cdot w_0 = n_0 z_0\). The remainder of the team output goes to
the senior as the senior's wage. Therefore:
\(w_1 = Q_{\text{team}} - n_0 w_0 = \frac{z_1}{h(1-z_0)} - n_0 z_0.\)
But recall \(n_0 = \frac{1}{h(1-z_0)}\) from (1). Plugging that in: 
\begin{equation}
w_1  =  \frac{z_1}{h(1-z_0)} ;-; \frac{1}{h(1-z_0)} ,z_0  = 
\frac{z_1 - z_0}{h(1-z_0)}. \tag{4}
\end{equation}

Thus in Case 1, {senior wage}
\(w_1 = \frac{z_1 - z_0}{h(1-z_0)}\), while {junior wage}
\(w_0 = z_0\). We observe that seniors capture all the {surplus}
from teamwork above what juniors could produce alone. Juniors are paid
just their solo productivity, and the extra output that comes from the
senior's guidance accrues to the senior. This wage structure reflects
the {bargaining power of scarce seniors}: they are the limiting
resource, so they can demand a high wage. The {wage ratio} here
is: 
\begin{equation}
\frac{w_1}{w_0}  =  \frac{z_1 - z_0}{hz_0(1-z_0)},.
\tag{5}
\end{equation}
This can be much larger than 1, indicating significant
inequality in favor of seniors when seniors are scarce.

{GDP in Case 1:} In aggregate, all \(L_1\) seniors will form
teams and produce \(\frac{z_1}{h(1-z_0)}\) each, while the leftover
juniors (those not in teams) work solo producing \(z_0\) each. The
number of juniors in teams is \(n_0 L_1 = \frac{L_1}{h(1-z_0)}\). If
\(L_0 > n_0 L_1\), then \(L_0 - \frac{L_1}{h(1-z_0)}\) juniors are
solo. So total output (GDP) is:
\(Y = L_1 \left(\frac{z_1}{h(1-z_0)}\right) + \left(L_0 - \frac{L_1}{h(1-z_0)}\right) z_0.\)
Simplifying, $ Y = \frac{L_1(z_1 - z_0)}{h(1-z_0)} +
L_0,z_0.$ The first term is output from teams (which equals total
senior wages \(L_1 w_1\)), and the second term is output from solo
juniors (equal to their wages \(L_0 w_0\)). This economy's GDP is
higher than it would be without teams, due to the productivity boost
of seniors collaborating with juniors.

We should note a {participation constraint}: seniors will only
agree to work in a team (bearing the hassle of mentoring) if they earn
at least what they could get by working solo. A senior's solo outside
option is \(z_1\). In Case 1, do they get at least that? The condition
\(w_1 \ge z_1\) implies: 
$$
\frac{z_1 - z_0}{h(1-z_0)} \ge z_1.
$$
This rearranges to 
\begin{equation}
z_1 ;\ge; \frac{z_0}{1 - h(1-z_0)},.
\tag{PC}
\end{equation}
This inequality is assumed to hold by parameter choice (the
problem statement notes we assume parameters such that the
participation constraint holds). Intuitively, it requires the senior's
skill advantage \(z_1 - z_0\) and the leverage factor \(1/[h(1-z_0)]\)
be large enough that team output exceeds the sum of what the senior
and juniors could do separately. If this holds, seniors willingly form
teams (it is indeed optimal for them). We will maintain this
assumption so that teamwork is viable; otherwise, if \(w_1 < z_1\), a
senior might prefer to dismiss the juniors and just solve problems
alone.
\item
{Case 2: Juniors are the bottleneck (Junior-scarce, ``Too many
seniors'').} Now consider the opposite situation: \(L_0 < n_0 L_1\).
There are not enough juniors to utilize all seniors' capacity. In
fact, in this case every junior can join a team, and some seniors will
still be left without a junior partner. Juniors become the scarce
factor. In equilibrium, junior wages will be bid {above} their
solo productivity because seniors compete to get them on their team.

Specifically, when seniors are abundant, a senior who fails to hire a
junior would have to work alone and earn \(z_1\). But a senior with a
junior (or ideally \(n_0\) juniors) can achieve higher output. So
seniors are willing to pay a premium to attract juniors. The
equilibrium will equalize the benefit: some seniors end up solo and
earn \(z_1\), while those with teams get the team output minus what
they paid juniors. In a competitive equilibrium, no arbitrage implies
a senior is indifferent between working solo or hiring juniors at the
going wage.

In Case 2, the {senior wage gets pushed down to their solo
output}: \(w_1 = z_1.\) Seniors are no longer capturing a big surplus;
if they tried to demand more, firms would just use an extra senior in
place of a costly one (since seniors are plentiful). Meanwhile,
{juniors capture all the surplus from teamwork}. The logic: a
junior joining a team enables the senior to go from \(z_1\) output
(solo) to \(\frac{z_1}{h(1-z_0)}\) output. That gain is
\(\frac{z_1}{h(1-z_0)} - z_1\). With juniors scarce, they can bargain
for (almost) that entire gain in their wage. Formally, if one senior
can only hire \(n_0\) juniors, the total team output minus the
senior's outside option is the pool to pay juniors. For one senior
with \(n_0\) juniors:
\(\text{Surplus from team} = \frac{z_1}{h(1-z_0)} - z_1.\) This must
equal the total premium paid to juniors above their next best option.
Juniors' next best is working solo for \(z_0\). So if the junior team
wage is \(w_{0,\text{team}}\), the premium per junior is
\(w_{0,\text{team}} - z_0\). With \(n_0\) juniors,
\(n_0 (w_{0,\text{team}} - z_0)\) should equal the surplus:
\(n_0 (w_{0,\text{team}} - z_0) = \frac{z_1}{h(1-z_0)} - z_1.\) Using
\(n_0 = \frac{1}{h(1-z_0)}\), this yields:
\(w_{0,\text{team}} = \frac{z_1}{h(1-z_0) n_0} - \frac{z_1}{n_0} + z_0 = \frac{z_1}{h(1-z_0)} \frac{1}{n_0} - \frac{z_1}{n_0} + z_0.\)
But \(1/n_0 = h(1-z_0)\). Simplifying:
\(w_{0,\text{team}} = z_1 [h(1-z_0)] - 0 + z_0 = z_0 + z_1 h(1-z_0).\)
Note \(h(1-z_0) < 1\), so \(w_{0,\text{team}}\) is between \(z_0\) and
\(z_1\). In fact, since typically \(z_1 \gg z_0\) and \(h\) might not
be extremely small, this wage can be substantially higher than
\(z_0\). In equilibrium, all juniors would receive this team wage
(because any junior not in a team could be hired by some senior for at
least this much). We can rewrite it as: 
\begin{equation}
w_0 = z_1[1 - h
(1-z_0)]. \tag{6}
\end{equation}
This is the {junior's wage in Case 2}.
They essentially get a cut of the senior's high productivity. The
{wage ratio} now is:
\(\frac{w_1}{w_0} = \frac{z_1}{z_1[1 - h(1-z_0)]} = \frac{1}{1 - h(1-z_0)}.\)
This ratio is \textgreater1 (since the denominator \textless1), but
notably it no longer depends on the skill gap \(z_1 - z_0\). In fact,
in this junior-scarce regime, the {relative wage is lower} than
in Case 1 if \(z_1 - z_0\) is significant. (Because in Case 1,
\(w_1/w_0\) grows with \(z_1\); in Case 2, \(w_1/w_0\) is fixed by
\(h\) and \(z_0\).)

Intuitively, when juniors are scarce, even a very high-skill senior
cannot command a huge premium because they desperately need juniors to
leverage their skill. Juniors then receive a large share of the value
(they ``capture the rent'' from the teamwork). By contrast, in
senior-scarce scenario, the senior could name their price since
juniors had nowhere else to get the premium.

In summary, our static model yields two distinct regimes for wage
inequality. {In Case 1 (many juniors), seniors capture most of
the surplus and inequality is high}. {In Case 2 (many seniors),
juniors get a larger share of the surplus, compressing the wage gap.}
This has interesting implications: for example, if an economy suddenly
increases the supply of seniors (say through education or immigration of
skilled workers), it could flip from Case 1 to Case 2, potentially
{reducing wage inequality}. Conversely, an influx of junior workers
without enough senior mentors could increase inequality.

We can also analyze how {technology changes} affect inequality.
For instance, improvements in communication technology (a lower \(h\))
make teams more efficient. In Case 1, a drop in \(h\) {increases}
\(w_1/w_0\) because it amplifies the senior's leverage (see Eq. 5: \(h\)
in the denominator increases the ratio). In Case 2,
\(w_1/w_0 = 1/[1-h(1-z_0)]\), which actually {decreases} as \(h\)
decreases (since \(1 - h(1-z_0)\) increases). Thus, if better IT reduces
mentoring time \(h\), the effect on inequality is ambiguous: {if
seniors are scarce (Case 1), inequality rises; if juniors are scarce
(Case 2), inequality falls.} This observation foreshadows what could
happen with AI, which can be seen as an extreme improvement in
``communication'' productivity (or even a replacement for juniors).

Another comparative static: raising the junior skill level \(z_0\)
(e.g.~better basic education for all workers) tends to {reduce
wage inequality} in both cases. In Case 1, Eq. (5) shows \(w_1/w_0\)
decreases if \(z_0\) increases (holding \(z_1\) fixed). In Case 2,
\(w_1/w_0 = 1/[1-h(1-z_0)]\) also decreases as \(z_0\) rises. The
intuition is that if juniors become more capable, the senior's relative
advantage shrinks, and juniors also solve more tasks themselves, making
the senior slightly less pivotal.

{(These insights are qualitatively in line with broader labor
literature: technologies that complement high-skill workers can increase
inequality if high-skill workers are scarce, but if lower-skill workers
improve their capabilities, the gap narrows.)}

\subsection{Introducing AI as a Team Member}\label{introducing-ai-as-a-team-member}

We now extend the model to include {AI (artificial intelligence)}
as a potential ``worker'' in the team. We consider an AI system that
functions similarly to a junior: it can attempt problems up to a certain
competence and pass on the rest. Let:

\begin{itemize}

\item
  \(z_A\) = the AI's ``skill'' (the maximum difficulty of problems the
  AI can handle). This could be interpreted as the quality or
  sophistication of the AI. For example, if \(z_A = z_0\), the AI is as
  good as a junior at solving problems; if \(z_A > z_0\), the AI might
  surpass a human junior in capability.
\item
  \(h_A\) = the communication time per problem between the AI and the
  senior. This represents the {time a senior must spend to review
  or integrate the AI's output on tasks the AI couldn't fully resolve}.
  Perhaps surprisingly, working with an AI might involve some overhead
  (interpreting AI suggestions, correcting errors). We assume \(h_A\)
  plays a similar role to \(h\) for human juniors, and likely \(h_A\) is
  also \textless{} 1 (AI can also save time, but not eliminate oversight
  entirely).
\end{itemize}

The key difference is {cost:} hiring an AI has essentially
{no wage cost}. The AI is like a machine -- we can assume it's a
fixed asset or its ``salary'' is zero for the marginal analysis (or its
cost is not a wage paid to a human). Thus, a senior who has access to AI
can use as many ``AI juniors'' as they want, limited only by time.

Suppose a senior can choose to work with {\(n_A\) units of AI}
(multiple AI instances or simply scaling usage). Similar to before, if
the senior allocates all their time to handling the AI's unsolved
problems: \(n_A (1 - z_A) h_A = 1,\) giving
\(n_A = \frac{1}{h_A(1-z_A)}.\) This mirrors (1). Essentially, a
single senior can now leverage up to \(1/[h_A(1-z_A)]\) AI processes in
parallel. The {output per senior with AI} would be: $
Q_\{\text{with AI per senior}\} = n_A z_A + n_A (z_1 - z_A) =
n_A, z_1 = \frac{z_1}{h_A(1-z_A)},. \tag{7}$ So substituting
``A'' for ``0'' in the earlier team formula, we see the structure is
analogous. If \(z_A\) and \(h_A\) are comparable to a junior's
\(z_0, h\), then an AI can similarly boost the senior's productivity.
{Importantly, however, the AI doesn't demand a wage or have an
outside option.} This can fundamentally alter the equilibrium.

Consider a scenario initially in Case 1 (too many juniors for available
seniors). In the {absence of AI}, seniors were teaming up with
juniors and paying them \(w_0 = z_0\). Now introduce a capable AI. A
senior could choose to {replace human juniors with AI} if it's
beneficial. The senior's decision will depend on whether using AI yields
a higher net output (since AI has no wage, net output = gross output).
Comparing senior's payoff in two options:

\begin{itemize}

\item
  Using human juniors: senior gets \(w_1\) as given in (4) which equals
  \(\frac{z_1 - z_0}{h(1-z_0)}\). (Recall this already subtracts the
  junior wages.)
\item
  Using AI: senior would get the entire output
  \(\frac{z_1}{h_A(1-z_A)}\) (since no juniors to pay).
\end{itemize}

The senior will prefer AI if: $ \frac{z_1}{h_A(1-z_A)}
;\textgreater; \frac{z_1 - z_0}{h(1-z_0)},. \tag{8}$ Rearranging,
this inequality is: $ \frac{h(1-z_0)}{h_A(1-z_A)} ;\textgreater; 1
- \frac{z_0}{z_1},. \tag{9}$

This condition says that the {relative efficiency} of AI (the LHS
is basically how many more tasks a senior can handle with AI vs with an
equivalent junior) exceeds a threshold related to the junior's
contribution (the RHS is the fraction of senior-solved tasks that
juniors cannot solve). If AI is equally as capable as juniors
(\(z_A = z_0\)) and equally easy to work with (\(h_A = h\)), then the
LHS of (9) simplifies to 1, and the RHS is \(1 - \frac{z_0}{z_1}\).
Since \(z_1 > z_0\), the RHS is positive, so (9) holds automatically.
This means {even if AI had the same skill and communication cost as
a junior, a senior would still prefer AI}, because with AI they don't
have to share output as wages. Essentially, as long as seniors have to
pay juniors at least something (and in Case 1 they pay juniors their
outside option \(z_0\)), an equivalent AI is more attractive due to zero
wage. The senior ``saves'' the junior wage cost and keeps the full
surplus.

Thus, {if AI is available, seniors will tend to replace human
juniors} for any configuration where the AI can do a comparable job. In
practice, AI might even have advantages: for instance, an AI could be
deployed in {unlimited quantity}. A senior is not limited to
\(n_0\) humans; if \(h_A\) is small enough, they could potentially use
more AI instances in parallel. In our simplified model we considered
using up to \(n_A = 1/[h_A(1-z_A)]\) AIs to fully use the senior's time
-- analogous to the human case -- but one can imagine that if AI scales
cheaply, a senior might handle even more (subject to fatigue or other
constraints). We will stick to the model's assumption that time is the
binding constraint.

Under condition (8), a {senior's optimal choice} is to employ AI
exclusively and {hire zero juniors}. In that outcome:

All juniors are effectively {pushed out} of teams. They must
either find solo work or remain underemployed. Given our model, they
would revert to working solo on problems (output \(z_0\) each).

Each senior now works with their AI helpers and produces output
\(\frac{z_1}{h_A(1-z_A)}\). The {senior's wage} would adjust to
reflect their new productivity (if seniors are still scarce, they
capture it; if seniors became abundant relative to remaining team
opportunities, wages might equalize differently, but presumably if all
seniors adopt AI, juniors are no longer a limiting factor at all).

We are especially interested in the {impact on output and wages}
in this scenario:

{Output per senior with AI} is given by (7) above. Comparing
(7) to the old team output (2), we see two changes: \(z_0\) is
replaced by \(z_A\), and \(h\) by \(h_A\). If AI is ``better'' than
juniors (say \(z_A > z_0\) or \(h_A < h\)), then obviously a senior+AI
team outperforms a senior+human team. But even if AI were equivalent
in skill and cost, the {allocation of surplus} differs -- seniors
now get {all} of it.

{Wages:} In the new equilibrium, what are wages? All juniors
are essentially relegated to solo work, earning \(w_0 = z_0\) (since
they can't command any premium; seniors aren't hiring them). Seniors,
using AI, can produce a lot more. If seniors remain the scarce factor,
one might expect \(w_1 = \frac{z_1}{h_A(1-z_A)}\) (the value of their
augmented output). However, if AI is sufficiently powerful, it might
increase the {effective supply of problem-solving capacity} such
that seniors are no longer so scarce. In our setting, since the number
of seniors hasn't changed, seniors likely still remain the only ones
who can solve the hardest problems, so they probably still earn a
premium. For simplicity, assume \(L_0\) is large enough (and juniors
not used) so that we remain in a regime analogous to Case 1: seniors
capture the surplus. Then: $ w_1 = \frac{z_1}{h_A(1-z_A)},
\qquad w_0 = z_0.$ The {wage ratio with AI} (under these
assumptions) becomes:
\(\frac{w_1}{w_0} = \frac{z_1}{h_A (1-z_A)  z_0}.\) This is
typically {even higher} than the original ratio (5), since
\(h_A\) is likely not greater than \(h\), and \(1-z_A \le 1-z_0\) if
\(z_A \ge z_0\). In words, if AI replaces juniors, {inequality
spikes}: seniors' productivity (and pay) shoot up, while juniors fall
back to low-productivity solo work earning \(z_0\). We've shifted to a
world somewhat akin to Case 1 (seniors with teams) but where the
``teams'' are AI and the juniors' labor is largely sidelined.

From a {static output} perspective, introducing AI in this way
unambiguously {raises GDP}. Previously, one senior with \(n_0\)
juniors produced \(z_1/[h(1-z_0)]\). Now each senior produces
\(z_1/[h_A(1-z_A)]\), which we are given is higher (since (8) held for
adoption). Plus, the juniors still produce something on their own (each
junior can still solve some easy problems solo, contributing \(z_0\)
each). So the new total GDP is:
\(Y_{\text{AI}} = L_1 \frac{z_1}{h_A(1-z_A)} + L_0  z_0.\) This is
{at least as large as} the no-AI GDP we wrote earlier, and indeed
greater given (8). Thus, in a static sense, AI raises efficiency -- no
surprise there. We get {more output} because seniors can handle
more problems faster with AI help, and juniors do what little they can
on their own.

However, static efficiency is not our sole interest. {The worry
is about dynamics: what happens over time if juniors never work with
seniors?} Juniors working solo do not learn from a mentor, potentially
stunting the creation of future seniors. The next section incorporates
this learning aspect.

Before moving on, we briefly consider: {What if juniors also have
access to AI?} So far, we assumed juniors couldn't use AI, which is why
they became redundant. But suppose juniors too could utilize AI tools in
their solo work. In reality, tools like ChatGPT or Copilot {augment
even relatively inexperienced workers}, helping them perform above their
usual skill level. If a junior with AI could effectively achieve a
higher skill (say solve problems up to difficulty \(z_0'\) where
\(z_0' > z_0\)), it might reduce the gap with seniors. It might allow
one junior+AI to handle tasks that previously required escalation to a
senior. This scenario could {change senior behavior}: instead of
entirely displacing juniors, seniors might still employ a smaller number
of juniors who are each more productive thanks to AI assistance. The
model would then treat the junior+AI bundle as having a higher effective
\(z_0'\) or lower effective time \(h\) needed. We won't formally analyze
this case here, but we note that {AI as a complement (augmenting
juniors)} has very different implications than AI as a pure substitute.
Indeed, recent empirical evidence suggests generative AI can {help
junior or less-skilled workers improve faster}, by disseminating best
practices and providing guidance. For instance, customer support agents
with AI assistance saw novices catch up to experienced workers more
quickly, moving ``down the experience curve'' faster. If juniors could
similarly learn faster with AI, then the dynamic loss might be
mitigated. The worst dynamic outcome arises when AI is {used
instead of training juniors}, not when it's used to support juniors. We
return to this point in the conclusion.

\subsection{Dynamic Considerations: Learning by
Mentoring}\label{dynamic-considerations-learning-by-mentoring}

Thus far, we treated the supply of seniors and juniors as fixed. We now
enrich the model with a {simple dynamic mechanism: juniors can
learn and become seniors over time by working in teams (being
mentored)}. This captures the idea of a {career progression or
on-the-job learning}: a junior who spends time collaborating with a
senior gradually acquires the senior-level skill. We model this as a
{Poisson process}: while working in a team under a senior, a
junior ``graduates'' to senior skill level at an instant rate
\(\lambda\). This promotion could be thought of as the junior
accumulating enough knowledge to handle the hardest problems, thus
effectively reaching skill \(z_1\). We assume if this happens, the
person is now a senior (skill \(z_1\)) from that point on. (In a
continuous-time overlapping generations model, one could formalize it,
but here we focus on steady state.)

For simplicity, let's consider a continuous-time steady state. People
are born at rate \(\delta L\) (so \(\delta\) is birth rate relative to
population) and die at rate \(\delta\) (ensuring a stationary population
\(L\)). A fraction \(\phi\) of new entrants are {exogenously}
high-skill (perhaps through education) and start as seniors, while the
rest \(1-\phi\) start as juniors. Without any on-the-job learning, the
economy's fraction of seniors would just be \(\phi\) in steady state.
However, {with learning by mentoring, additional seniors are
created from juniors' ranks} each period.

In steady state, the {stock of seniors \(L_1\)} evolves according
to: new seniors come from two sources -- the \(\phi \delta L\) who are
born as seniors, and those promoted via learning -- and seniors exit due
to death. Because at steady state \(L_1\) is constant, we have:
\(\delta L_1 = \delta L\phi + \text{(promotions from junior to senior per unit time)}.\)
How many promotions occur? Only juniors {working on teams} with
seniors can learn at rate \(\lambda\). If a junior is working solo,
there is no senior to learn from, so we assume no progression (one could
assume some slower self-learning, but our focus is the mentorship
channel). In Case 1 (the relevant case, as we will assume seniors are
scarce enough to have full teams formed), the number of juniors in teams
with each senior is \(n_0 = \frac{1}{h(1-z_0)}\). So per senior,
promotions happen at rate \(\lambda n_0\) (since each junior has rate
\(\lambda\)). Across all seniors \(L_1\), promotions =
\(L_1 \lambda n_0\). We equate this to senior deaths + outflow:
\(\delta L_1 = \delta L \phi + L_1 \lambda n_0.\)

Divide through by \(\delta L\) to get seniors as a fraction of
population \(L_1/L\):
\(\frac{L_1}{L} = \frac{\phi + \frac{\lambda}{\delta} \frac{L_1}{L} n_0}{1}.\)
Solving, $ \frac{L_1}{L} =
\frac{\phi}{1 - \frac{\lambda}{\delta} n_0},. \tag{10}$

This is the steady-state share of seniors including the effect of
learning. Because \(n_0 = \frac{1}{h(1-z_0)}\), we can rewrite the
denominator as \(1 - \frac{\lambda}{\delta}\frac{1}{h(1-z_0)}\). As long
as \(\frac{\lambda}{\delta} < h(1-z_0)\), this fraction is well-defined
(less than 1 in numerator). We assume {learning is slow relative
to exit} so that not everyone ends up a senior (i.e.~\(\lambda\) is not
too high). This condition was earlier given as
\(\frac{\lambda}{\delta} < (1-\phi)h(1-z_0) - \phi\) to ensure
consistency with Case 1 (seniors remain scarce despite learning).
Essentially, as long as seniors do not become too common (which would
flip us to Case 2), our analysis holds.

Notably, (10) implies: \(\frac{L_1}{L} > \phi,\) since
\(\frac{\phi}{1 - x} > \phi\) for any \(x>0\). {Learning by
mentoring raises the long-run proportion of high-skill workers.} In
effect, some juniors ``graduate'' to senior roles faster than they are
aging out. This is a positive externality of teamwork: it increases the
economy's human capital over time. The faster the learning rate
\(\lambda\) or the larger the teams (higher \(n_0\)), the greater the
boost to \(L_1/L\). If \(\lambda \to 0\), we recover \(L_1/L = \phi\).
If \(\lambda\) is very large (approaching the threshold where
denominator → 0), \(L_1/L\) can be substantially above \(\phi\) (though
we keep it below the Case 1 to Case 2 flip point).

What is the {steady-state output per capita} without AI? Using
the same approach as static but weighting by the new \(L_1, L_0\), we
have:
\(\frac{Y_{\text{no AI, steady}}}{L} = \frac{L_1}{L} \frac{z_1 - z_0}{h(1-z_0)} + \frac{L_0}{L} z_0.\)
Substitute \(L_1/L\) from (10) and \(L_0/L = 1 - L_1/L\):

\begin{align*}
\frac{Y_{\text{no AI}}}{L} &= \frac{\phi}{,1 - \frac{\lambda}{\delta h(1-z_0)},} \cdot \frac{z_1 - z_0}{,h(1-z_0),} ;+; \Big[1 - \frac{\phi}{,1 - \frac{\lambda}{\delta h(1-z_0)},}\Big] z_0 \\
&= z_0 ;+; \frac{\phi (z_1 - z_0)}{,h(1-z_0) - \frac{\lambda}{\delta},} ;-; \frac{\phi, z_0}{,1 - \frac{\lambda}{\delta h(1-z_0)},},.
\end{align*}

After some algebra, this simplifies to: $ \frac{Y_{\text{no AI}}}{L} =
z_0 ;+;
\phi \frac{z_1 - z_0[1 + h (1-z_0)]}{h(1-z_0) - \frac{\lambda}{\delta}},.
\tag{11}$ One can verify that \(\partial (Y/L)/\partial \lambda > 0\);
increasing the learning rate \(\lambda\) raises steady-state output per
capita (because more workers end up as high-skill). In the limit of no
learning (\(\lambda=0\)), (11) reduces to
\(z_0 + \phi\frac{z_1 - z_0}{h(1-z_0)}\), which corresponds to each
senior producing their static team output and juniors remaining juniors
forever.

Now consider the steady state {with AI}. If seniors use AI
exclusively and juniors never join teams, {no on-the-job learning
occurs} (juniors have no mentors). The fraction of seniors in the long
run will then remain \(\phi\) -- essentially, the only seniors are those
who were initially endowed with high skill, since no new ones are
trained. Thus \(L_1/L = \phi\) in the long run with AI (we assume AI
adoption eliminates the mentoring pathway). Each senior still produces a
high output \(\frac{z_1}{h_A(1-z_A)}\) with AI. Juniors remain juniors
(fraction \(1-\phi\) of pop) and work solo for output \(z_0\) each. So
the {steady-state per-capita output with AI} is: $
\frac{Y_{\text{AI, steady}}}{L} = \phi \frac{z_1}{h_A(1-z_A)} +
(1-\phi) z_0. \tag{12}$

The crucial question is: {which steady state yields higher output,
with or without AI?} It is not obvious because {AI boosts current
productivity} (especially of seniors) but {eliminates the
learning that boosts future human capital}. If learning effects are
small (either \(\lambda\) low or \(z_1 - z_0\) not too large), the
AI-gained output may dominate. But if learning effects are powerful,
losing them can outweigh AI's static gain in the long run.

Comparing (12) and (11) is a bit messy in general. However, we can
derive a condition for when introducing AI {reduces long-run GDP
per capita}: \(\frac{Y_{\text{AI}}}{L} < \frac{Y_{\text{no AI}}}{L}.\)
Using the expressions above, one key case to consider is when seniors
{do} choose to use AI (so condition (8) holds) -- otherwise AI
wouldn't be adopted at scale. Under condition (8), we indeed have
\(Y_{\text{AI (static)}} > Y_{\text{no AI (static)}}\) initially. But as
\(\lambda\) increases, \(Y_{\text{no AI (steady)}}\) grows, while
\(Y_{\text{AI (steady)}}\) stays the same (since it doesn't benefit from
\(\lambda\)). There will be a threshold \(\lambda\) beyond which
\(Y_{\text{no AI steady}} > Y_{\text{AI steady}}\). In other words,
{for sufficiently high learning rates or long-term
considerations, AI adoption could lead to a lower steady-state output}
than a scenario with no AI but continual skill development.

Deriving the precise inequality, from (11) and (12), one condition for
\(Y_{\text{AI}}/L < Y_{\text{no AI}}/L\) turns out to be: $
\frac{z_1}{h_A(1-z_A)} - z_0 ;\textless;
\frac{z_1 - z_0}{h(1-z_0) - \frac{\lambda}{\delta}} -
\frac{z_0}{1 - \frac{\lambda}{\delta h(1-z_0)}}. \tag{13}$ This
expression basically asks whether the {AI-driven senior output
advantage} (\(\frac{z_1}{h_A(1-z_A)} - z_0\), i.e.~how much more a
senior+AI produces over a junior's output) is smaller than the
{mentoring-driven output advantage} (the right-hand side is
roughly the additional output per capita gained from having more seniors
via learning). If the learning term is large (high \(\lambda\)), the
inequality can hold even if AI has a strong static benefit.

To give intuition: if \(\lambda = 0\) (no learning), the RHS of (13)
reduces to \(\frac{z_1 - z_0}{h(1-z_0)} - z_0\), which is exactly $
\frac{z_1}{h(1-z_0)} - (z_0 + \frac{z_1 - z_0}{h(1-z_0)}) =
\frac{z_1}{h(1-z_0)} - \frac{z_1}{h(1-z_0)} = 0$. So the inequality
says AI decreases output if $ \frac{z_1}{h_A(1-z_A)} - z_0 \textless{}
0$, which would {never} be true if \(z_1 > z_0\). So with
\(\lambda=0\), AI always helps or at least doesn't hurt output (as
expected). As \(\lambda\) grows, the RHS increases, eventually possibly
exceeding the LHS.

In short, {dynamic losses from the lack of learning can outweigh
static gains from AI} beyond some tipping point. This highlights a
potential {dynamic inefficiency}: individual firms or seniors may
adopt AI because it is privately optimal at time 0 (it yields higher
output and profit for them), but collectively this might lead to lower
output in the long run due to a collapse in human capital formation.
There is a parallel here to the idea of {excessive automation}
noted by some economists -- that firms adopt labor-saving technology
beyond the socially optimal level because they do not internalize the
loss of future skilled workers or the broader consequences on the labor
market (Acemoglu \& Restrepo, 2020; Korinek, 2023). Our model provides a
microfoundation for one such consequence: {foregone
learning-by-doing}.

It is worth mentioning that our analysis is somewhat one-sided in that
{we did not allow AI itself to improve} over time in this model.
In reality, AI could also become more capable by learning from data
(including data generated by humans). Some theorists describe advanced
AI as having a ``learning-by-using'' dynamic -- the more it's used, the
more it learns from human decisions, potentially {accelerating} its
capability growth. A recent NBER paper conceptualizes AI in this way and
warns that AI might initially complement workers but eventually
substitute them as the AI becomes very skilled. That dynamic is
different from ours (where humans learn, not AI), but it also leads to
time-varying impacts on labor. In their model, wages might rise
initially and then fall as AI crosses a certain threshold. In our model,
wages for juniors might rise initially (if juniors are scarce) but then
collapse if AI adoption becomes ubiquitous and no new seniors emerge.

We have so far assumed that juniors {do not internalize} the future
benefit of learning when bargaining. What if they {anticipate the
career progression} and are willing to accept lower current wages for a
chance to become seniors? This introduces an interesting twist: juniors
might essentially ``pay for'' their training by working at a discount.
In a competitive labor market with forward-looking workers, the junior's
expected lifetime utility from a team position should equal that from
working solo (or elsewhere). If \(J\) denotes the expected {present
value} of being a junior on a team, we can write a {Bellman
equation}:
\(\delta J = w_{0,\text{team}} + \lambda [\frac{w_1}{\delta} - J],\)
where \(\frac{w_1}{\delta}\) is the capitalized value of becoming a
senior (earning \(w_1\) per period indefinitely, for simplicity).
Meanwhile, the value of being a solo junior is
\(J_{\text{solo}} = \frac{z_0}{\delta}\) (earning \(z_0\) forever, no
promotion). Indifference requires \(J = J_{\text{solo}}\). Solving the
Bellman:
\(J = \frac{w_{0,\text{team}} + \lambda \frac{w_1}{\delta}}{\delta + \lambda},\)
and setting \(J = z_0/\delta\), we get: $ w_\{0,\text{team}\} = z_0 -
\frac{\lambda}{\delta}(w_1 - z_0). \tag{14}$ This means juniors on a
team might accept a wage {below} \(z_0\) (their static marginal
product) if \(w_1 > z_0\) and \(\lambda>0\), because they expect to
recoup it when they become seniors. In other words, they effectively pay
the senior (or firm) for training via a wage discount. If firms can
commit to long-term contracts or juniors are confident in promotion,
such an equilibrium could occur. It resembles classic ``apprenticeship''
where trainees work for low pay to gain skills.

If (14) holds, the senior's surplus from a team is even larger because
juniors are cheaper labor. In fact, substituting this
\(w_{0,\text{team}}\) into the senior's team wage formula, one finds:
\(w_1 = \frac{z_1}{h(1-z_0)} - n_0 w_{0,\text{team}} = \frac{z_1}{h(1-z_0)} - \frac{1}{h(1-z_0)}\Big(z_0 - \frac{\lambda}{\delta}(w_1 - z_0)\Big).\)
Solving for \(w_1\) gives: $ w_1 =
\frac{\frac{z_1 - z_0}{h(1-z_0)} + \frac{\lambda}{\delta}\frac{z_0}{h(1-z_0)}}{1 + \frac{\lambda}{\delta h(1-z_0)}}.
\tag{15}$ This is the senior wage when juniors fully internalize
learning (in equilibrium \(w_1\) is determined by a fixed point). One
can check that this \(w_1\) is lower than the previous
\(w_1 = \frac{z_1 - z_0}{h(1-z_0)}\); juniors' willingness to work for
less transfers some rent back to themselves (or to the firm).
Essentially, seniors can't exploit juniors as much if juniors are
strategically considering their future payoff.

Now, how does this affect the decision to adopt AI? If juniors are
already willing to undercut their wage for training, a senior's private
benefit of replacing them with AI is smaller. We would modify the
{AI adoption condition} (8) to compare \(w_1\) from (15) (team
with learning-internalizing juniors) to the AI output. The condition for
AI use becomes: $ w_1 \text{ (with learning-internalizing juniors) }
\textless{} \frac{z_1}{h_A(1-z_A)}. \tag{16}$ Substituting (15) for
\(w_1\), this inequality is more complex, but the key insight is:
{if juniors value learning, they effectively subsidize the team,
making seniors less eager to drop them for AI}. In fact, seniors might
stick with human teams even when AI is somewhat better, as long as the
juniors' wage is depressed enough that the senior's net payoff is
comparable. There is even a possibility that a {senior might
{personally prefer} to keep juniors instead of AI}, to maintain the
flow of future rents from those juniors when they become seniors. This
hints at a kind of {rent-seeking behavior}: an incumbent senior
might resist a labor-saving technology (AI) not because it's bad for
productivity, but because adopting it would break the cycle that allows
them to capture rents from the next generation. This is reminiscent of
scenarios in industrial organization where incumbents deter entry or new
technology to preserve future monopoly rents. In our labor context, the
senior might forego an immediate productivity gain from AI in order to
continue benefiting from cheap junior labor and possibly a share in
their future success (if there's some way seniors benefit from having
trained successors -- e.g., in a firm hierarchy or partnership model).
This particular strategic angle goes beyond our basic model, but it's an
intriguing possibility for extension.

\subsection{Discussion: Related Literature and Policy
Implications}\label{discussion-related-literature-and-policy-implications}

Our model highlights a {dynamic externality} in the adoption of
AI in skilled work: the loss of learning opportunities for junior
workers. This connects to several strands of literature:

{Learning-by-doing and dynamic inefficiencies:} The idea that
current production can build future human capital has a long history
in economics (Arrow, 1962; Lucas, 1988). In those models, firms or
workers do not fully internalize the benefit of the skills they
accumulate for society's future, leading to underinvestment in
learning. In our setup, the externality is explicit: when a senior
chooses AI over mentoring a junior, the senior ignores the fact that
one less junior will become a high-skill worker. This is a social loss
not reflected in the senior's private payoff. Our results echo themes
in Acemoglu's work on automation: he argues that there can be
{excessive automation} because firms adopt cost-saving
technologies without considering the negative effect on workers' skill
acquisition and earnings. Acemoglu \& Restrepo (2018, 2020) emphasize
that automation needs to be counterbalanced by new tasks for labor;
otherwise, workers get displaced and aggregate gains may be smaller
than anticipated. In our model, training juniors can be viewed as
creating ``new skilled workers'' (akin to new task opportunities for
labor in the future). If AI halts that, the long-run supply of skilled
labor is lower, potentially reducing innovation or productivity down
the line.

{Rent-seeking and optimal incentives:} We drew a parallel to an
insight by Buera and co-authors (2025). They study dynamic competition
in oligopolies and find that private incentives can deviate from
social optima due to dynamic considerations (firms do not internalize
the full social benefit of more competition or innovation). However,
they also show that {dynamic competition alone doesn't always
justify intervention} -- in some cases the equilibrium can be
constrained-efficient. The analogy in our context would be: is the
private outcome (seniors replacing juniors with AI) inefficient, or
could it be constrained-efficient? If seniors are scarce and capture
rents, they undervalue the creation of new seniors (since that would
erode their future rents). This likely leads to {under-provision
of training} relative to the social optimum. Even if seniors
internalize juniors' learning (via lower wages), the senior is just
extracting that value; the junior's presence still creates a positive
externality for others (e.g., future firms or the economy benefit from
having more skilled workers beyond the senior's own firm). Thus, we
suspect the market equilibrium is tilted toward too much AI adoption
from a social viewpoint, whenever learning externalities are
significant. This is a form of dynamic inefficiency where regulators
or policy might want to intervene -- akin to subsidizing training or
taxing automation. Buera et al.'s framework is different (firms and
innovation), but the common theme is balancing static gains with
dynamic considerations. In Buera's model, the government might
subsidize entrants to maintain competition; in our model, one could
imagine {incentives for firms to hire and train juniors} even
if AI is available, to sustain human capital formation.

{Evidence on AI's impact on training and skills:} Given that
generative AI is a very recent technology, hard empirical evidence on
long-run skill dynamics is limited. However, early studies and surveys
provide hints:

As noted earlier, Hess et al.~(2023) find that in jobs with high
automation risk, {workers and firms invest less in training}.
This aligns with our model's implication that firms might cut back
on developing junior talent if they plan to automate roles.
Muehlemann (2024) finds that {AI adoption in German firms led
to reduced training for current workers, but an increase in
apprenticeship contracts}. The latter suggests some firms anticipate
needing skilled workers who know how to work with AI, so they ramp
up apprentice programs. In our terms, that would be like trying to
ensure juniors are still coming up the pipeline, perhaps in a more
AI-centric way.

There is anecdotal evidence of companies {reducing
entry-level hiring} because of AI. For example, some law firms have
slowed hiring of junior lawyers as AI can do first drafts of
contracts and research. In programming, one hears quotes like
{``why hire juniors when a single senior with AI can do the
job?''}. Our model formalizes the logic behind such quotes. But
commentators warn that this is short-sighted: junior roles today are
how seniors of tomorrow are created.

On the flip side, AI tools might serve as a {training device}.
The study by Brynjolfsson et al.~(2023) provides
{``proof-of-concept'' that generative AI can supplement human
learning}: in customer support, novice workers improved markedly
with AI help, essentially learning from AI's suggestions. Noy and
Zhang (2023) found less-skilled writers improved their writing
quality using ChatGPT, closing some gap with more-skilled writers.
These findings suggest a possible {complementary} path: instead
of replacing juniors, firms could give juniors AI tools to make them
productive and accelerate their learning. In our model's terms, that
would keep \(\lambda\) (learning) alive while also enjoying some of
AI's static benefits -- a potential win-win if done right.

{Policy responses:} If indeed there is a danger that the
pipeline of skill formation gets broken, what policies could mitigate
this? One idea is {incentivizing human-complementary uses of
AI} over pure automation. Acemoglu et al.~(2023) argue for directing
innovation towards augmenting workers rather than replacing them.
Concretely, they suggest measures like:

Adjusting the {tax code}: currently, in the U.S., companies
can often save costs by investing in software/AI (capital) rather
than hiring workers, due to how labor is taxed (payroll taxes,
etc.). Making taxes neutral between hiring a person and deploying an
AI could remove an artificial incentive to cut jobs. Equivalently,
one could offer tax credits for training expenses or for maintaining
apprentice programs. If firms faced the true long-run cost of lost
human capital, they might choose a more balanced approach.

{Training subsidies or requirements}: Governments could
subsidize firms that provide robust training to young workers, or
even mandate industries (like law, medicine) to maintain certain
residency/internship positions. Historically, some professions have
{guild-like systems} to ensure knowledge transfer. In an AI
era, we might need updated versions of these to ensure juniors still
get experience, perhaps focusing on tasks AI can't do (or overseeing
AI).

{Worker voice and bargaining}: The CEPR columnsuggests that
giving workers more voice in tech implementation decisions could
help steer AI adoption in a worker-friendly direction. If junior
employees (or their unions) had a say, they might push for AI that
{helps them} rather than replaces them, or for maintaining
pathways to advancement. This is of course challenging if the
juniors are never hired to begin with -- a catch-22 -- but it speaks
to the need for broader stakeholder involvement.

{Ensuring new task creation}: In the long run, entirely new
roles might emerge that juniors can fill and learn in, even if old
entry-level tasks are done by AI. For example, if AI handles coding,
perhaps {prompt engineering} or {AI supervision} becomes
the entry role. Some optimists believe AI will create more demand
for human judgment and soft skills, which could form the basis of
new junior positions. Our model does not incorporate new task
creation, but if we did, it could alleviate the dynamic loss
(Acemoglu \& Restrepo (2019) stress that new tasks for humans
historically accompanied automation). There may be a need for
{policies that encourage the development of new complementary
jobs} -- e.g., funding for R\&D in areas where humans can expand
work with AI rather than be replaced.

{Long-term distributional effects:} Our model has implications
for inequality that resonate with ongoing debates. In the short run,
AI may increase the productivity of top-skilled workers (seniors),
increasing the wage gap if they capture that value. Indeed,
{inequality could rise sharply} if AI is used in the Case 1
scenario. Acemoglu's recent paper (2024) suggests that even if AI
makes lower-skilled workers more productive in some tasks, it might
{still} increase inequality unless it's creating whole new
opportunities. Our model's Case 1 outcome with AI is an example:
juniors might improve a bit with AI, but if they're largely sidelined,
the gap widens. However, if juniors are scarce (Case 2), they could
benefit and inequality could decrease, at least initially. Over the
long run, if the supply of skilled workers doesn't grow (or even
shrinks relative to population because of no learning), we could see a
form of {skill premium persistence} or even a decline in
overall innovation. There is also a parallel to the literature on
{human capital and growth}: if one generation doesn't pass on
skills to the next, you can get stagnation. This is somewhat analogous
to some low-development traps where lack of skill transfer keeps
productivity low.

In terms of {empirics}, this is a nascent area. It will be
interesting to see in a decade whether industries that heavily adopted
AI early (like perhaps software coding or customer service) have a
missing cohort of mid-level professionals. Will companies regret not
training people? Or will AI evolve so rapidly that many traditional
senior roles themselves change or become obsolete, making the old
``pyramid model'' of organization unnecessary? Some have speculated
about a future with {very flat organizations}: a few
super-experts (plus AI) do all the work, and everyone else finds other
things to do. Others argue that human oversight and creativity will
remain in demand, preserving the need for career progression.

\subsection{Conclusion}\label{conclusion}

We developed a stylized model of an economy with high-skill ``seniors''
and low-skill ``juniors'' to investigate the impact of AI on
productivity and skill formation. The model yields several insights.
{First}, in a static setting, teams of juniors and seniors are
highly productive, and the division of surplus depends on their relative
supply. Seniors capture most gains when they are scarce, but if juniors
are scarce, they can command higher wages. {Second}, AI can act
like a super-efficient junior (requiring less time \(h_A\) and possibly
having higher skill \(z_A\)), which makes it privately optimal for
seniors to replace human juniors in many cases. This raises short-run
output and can either increase or decrease wage inequality depending on
the labor supply situation -- though a likely outcome is increased
inequality with seniors earning much more. {Third}, and most
importantly, the removal of juniors from teams means the {loss of
a key learning channel}. In our dynamic extension, junior-senior teams
were the engine of creating new skilled workers (future seniors). If AI
displaces this, the economy could suffer a {lower steady-state
level of human capital and output}, despite the initial AI-induced
boost. We derived conditions under which long-run GDP per capita falls
with AI, even though short-run GDP rises.

These findings underscore a potential {trade-off between present
and future productivity}. Our model is admittedly abstract -- reality is
more complex, with many tasks and continuous skill development -- but it
captures the essence of a concern raised by practitioners: {``Where
will the experts of tomorrow come from if nobody hires juniors
today?''}. The model also resonates with historical anecdotes. For
instance, in professions like crafts or medicine, when training
pipelines broke down, it led to skill shortages until corrective
measures were taken (sometimes through public intervention). We might be
at risk of a similar phenomenon in modern knowledge industries with
generative AI.

We should note some {limitations and open questions} in our
analysis:


We treated \(z_1, z_0, z_A, h, h_A\) as exogenous. In reality, these
could evolve. For example, \(z_A\) might improve over time as AI
learns from data (as per Wang \& Wong (2025) scenario). Also, human
skills \(z_0, z_1\) could respond to the presence of AI (educational
systems might train people differently if certain tasks are
automated). Incorporating such feedback is an important extension.

We assumed learning \(\lambda\) happens only through mentoring. Could
there be alternative pathways? Perhaps juniors could learn from AI (a
form of AI-driven training). If an AI can codify expert knowledge,
maybe juniors could acquire skills faster on their own. This would
mitigate the dynamic loss. Preliminary evidence (e.g., improved novice
performance with AI tools) gives credence to this possibility.
However, skeptics counter that true expertise often requires rich
tacit knowledge that comes from experience, not just AI advice. More
research (empirical and theoretical) is needed to understand AI's role
as a teacher vs.~as a crutch that {prevents} learning (as seen in
education contexts where students over-rely on AI and don't learn the
material).

Our equilibrium analysis with learning didn't delve into strategic
behavior much (except a brief mention of juniors internalizing
learning). In a dynamic game, one could ask: will seniors
{under-invest in training} juniors or even intentionally not pass
on knowledge to remain valuable (the classic ``knowledge hoarding''
problem)? How might that interact with AI adoption (since an
alternative to hoarding is just not having juniors at all)? These
nuances could be important in assessing whether the market
under-provides learning opportunities.

Finally, there's the question of {policy and welfare}: if we
determined that AI adoption is dynamically inefficient (i.e., society
would be better off in the long run if some juniors were trained),
what is the best way to achieve that? A blunt ban on AI in certain
tasks seems unlikely and inefficient. Incentive-based approaches (like
training subsidies or tax adjustments) are more promising and were
discussed above. One could formally model a social planner or
government that values future productivity and see what the optimal
intervention would be. This intersects with the literature on R\&D
policy and human capital externalities.

To conclude, our model provides a theoretical framework to think about
the {long-term consequences of AI on the labor force's skill
composition}. It suggests that even if AI brings immediate gains, we
should be vigilant about its impact on {career dynamics and
learning}. The full impact of generative AI on the workforce will play
out over decades; by combining insights from models like ours with
empirical monitoring, policymakers and firms can hopefully steer toward
outcomes where AI technologies {augment} human capabilities and
sustain growth, rather than create a short-lived spike in productivity
followed by stagnation due to missing human expertise. The evolving
literature -- from Buera et al.'s work on dynamic competition to
Acemoglu et al.'s calls for human-centric AI deployment -- all point to
a common message: {do not ignore the dynamic effects}. Our
contribution is to highlight the apprenticeship dimension of those
dynamic effects in the age of AI, an area that will surely benefit from
further research and data in the coming years.


\section*{References}\label{references}
\begin{itemize}

\item
  Buera, F. et al.~(2025). {The Life-cycle of Concentrated
  Industries}. (EFG Draft). {[}We refer to dynamic efficiency analysis
  in this paper.{]}
\item
  Heß, P., Janssen, S., \& Leber, U. (2023). {The effect of
  automation technology on workers' training participation}.
  {Economics of Education Review, 96}, 102438. {[}Finds workers
  exposed to automation are significantly less likely to receive
  training.{]}
\item
  Mühlemann, S. (2024). {AI Adoption and Workplace Training}. IZA
  Discussion Paper No.~17367. {[}Shows AI-adopting firms cut training
  for current workers and hire more skilled workers, but also increase
  apprenticeships in SMEs.{]}
\item
  Brynjolfsson, E., Li, D., \& Raymond, L. (2023). {Generative AI
  at Work}. NBER Working Paper 31161 (rev. Nov 2023). {[}Field
  experiment with customer support agents; AI boosted productivity 14\%,
  especially for novice workers, and helped disseminate expert best
  practices.{]}
\item
  Acemoglu, D. (2024). {The Simple Macroeconomics of AI}. (Working
  Paper, April 2024). {[}Argues modest productivity gains from AI and
  that AI could increase capital share; also notes AI can increase
  inequality even if it improves some low-skill productivity.{]}
\item
  Acemoglu, D., Johnson, S., \& others (2023). {Human-Centric AI}
  (CEPR Policy Insight No.~124). {[}Advocates for AI that complements
  workers; discusses policy changes like tax reform to encourage
  hiring/training over pure automation.{]}
\item
  Wang, P., \& Wong, T.N. (2025). {Artificial Intelligence and
  Technological Unemployment}. NBER Working Paper 33867. {[}Model of AI
  as learning-by-using; scenarios of AI initially complementing then
  substituting labor.{]}
\item
  Appelo, J. (2025). ``AI Wrecks the Corporate Career Ladder. Give
  Juniors the Steering Wheel!'' {The Maverick Mapmaker} (Medium,
  Mar 26, 2025). {[}Discusses how firms dropping junior hiring due to AI
  threatens apprenticeship and innovation; provides a practitioner
  perspective.{]}
\end{itemize}
\end{itemize}
\end{document}