\documentclass[12pt]{article}
\usepackage{a4,color,palatino,amsmath,amsthm,natbib,amssymb,graphicx,setspace}
\usepackage{tikz,colortbl}
\usepackage{tabularx}
\usepackage{graphicx}
\setlength{\parindent}{0pt}
\usepackage[gen]{eurosym}
\usepackage{subcaption}
\usepackage{fullpage}
\usepackage{booktabs}
\usepackage{float}


\linespread{1.5}


\title{AI, Teamwork, and the Dynamics of Skill Formation in the Workplace}
\author{Zsófia Bárány and Miklós Koren\thanks{This version of text written by OpenAI o3 based on our model notes and deep research prompts.}}
\date{June 19, 2025}

\begin{document}
\maketitle
\begin{abstract}
This paper develops a dynamic model of workplace skill formation under AI adoption. AI can substitute for junior workers, boosting short-run productivity but disrupting the apprenticeship ladder that produces future senior talent. We analyze how team production, learning-by-doing, and AI capabilities interact to shape wages, inequality, and long-run output. While AI enhances senior productivity, its displacement of juniors may lead to lower human capital in steady state. We derive conditions under which the dynamic loss outweighs the static gain, and discuss implications for inequality, labor market design, and optimal policy. The model highlights trade-offs between immediate efficiency and long-term skill development.
\end{abstract}
\section{Background and Motivation}\label{background-and-motivation}

The rapid rise of artificial intelligence (AI), especially generative AI, is reshaping how work is organized. One notable trend is the {replacement of entry-level roles by AI tools}. Many companies have reportedly stopped hiring interns and junior employees, choosing instead to rely on AI to handle tasks that junior staff used to perform. For example, {senior lawyers now use AI to draft contracts}, and {expert software developers leverage AI code generators (like GitHub Copilot) to write code}, rather than delegating these tasks to junior colleagues. Managers applaud the productivity spike -- {smaller teams delivering faster with AI assistance} -- and question the need for juniors in such a workflow. 

While this {AI-driven productivity boost} is real (field studies show generative AI can raise worker output by 14\% on average), there is
growing concern about {long-term consequences}. If firms cut junior positions, {who will become the next generation of experts?}
As one commentator put it, {``what happens when the seniors leave?
Who takes over their work?''}. In traditional organizations, juniors
learn from seniors via an {apprenticeship model}, gradually
acquiring the expertise to step into senior roles. AI threatens to break
this {career ladder}. The worry is that {lack of
on-the-job learning opportunities} for juniors could lead to a future
shortage of skilled seniors, and a loss of tacit knowledge that comes
from experience. Juniors also bring fresh perspectives and ``beginner's
mind'' questions that spur innovation -- benefits that may be lost if
only seasoned workers and AI are in the room.

Early evidence from labor economics supports these concerns.
{Automation appears to reduce human capital investment:} one
study finds workers whose jobs are at risk of automation are {15
percentage points less likely to participate in training} than similar
workers not exposed to automation. Firms facing automation tend to
{cut training for incumbent workers}, possibly because they
expect AI to take over tasks. In a recent IZA study, companies adopting
AI reduced continuing training for their staff, while hiring more
already-skilled workers instead. This behavior contributes to a
{``skills gap''} or polarization: fewer mid-skill workers being
developed, and a greater reliance on a small pool of high-skill experts.
On the other hand, some firms did increase {apprenticeships} even
as they adopted AI, suggesting awareness that {future workers still
need preparation for an AI-driven workplace}. These mixed findings
underscore the central trade-off: AI can raise current productivity, but
might undermine the {learning-by-doing} that builds future
productivity.

Our work develops a simple economic model to study this trade-off. We
ask: {Could the use of AI in teams lead to ``dynamic losses'' by
halting the development of human skills?} Conversely, under what
conditions can AI be integrated without depriving the next generation of
experience? We build on a framework of team production with
{senior (high-skill) and junior (low-skill) workers}, extending
it to include an AI ``worker.'' We analyze how AI affects output, wages,
and inequality in the short run, and then examine the long-run steady
state when junior workers normally learn from seniors over time. This
model helps clarify when AI is a complement that {augments
workers} versus when it becomes a substitute that {hollows out
career progression}.

In what follows, we first describe the baseline model of teams and skill
hierarchy. We then derive the equilibrium outcomes in two regimes (when
juniors are plentiful vs.~when seniors are plentiful) and discuss how
technology (communication efficiency, AI) affects productivity and wage
inequality. Next, we introduce AI as a special kind of ``free junior''
and determine when seniors would prefer AI over human juniors. Finally,
we incorporate {dynamic mentoring (learning)} into the model --
juniors can become seniors by working in teams -- and explore how the
presence of AI alters the long-run supply of skills and overall output.
Throughout, we connect our findings to recent literature. In particular,
we relate the {rent-seeking behavior and learning externalities}
in our model to the dynamic efficiency considerations highlighted by
Buera et al.~(2025), and we situate our results in the broader
discussion on AI's impact on the labor market (e.g.~Acemoglu \&
Restrepo, Korinek, etc.) with an emphasis on the potential {dynamic
losses from a lack of learning opportunities}.

\section{Model Setup: Skill Levels, Tasks, and Team Production}\label{model-setup-skill-levels-tasks-and-team-production}

\paragraph{Problems and skills.} We consider an environment where problems (or tasks) have varying difficulties. Formally, let task difficulty \(Z\) be uniformly distributed on \([0,1]\). A worker's skill level \(z\in(0,1)\) represents the hardest problem that they can solve. In other words, a person with skill \(z_i\) can solve any problem of difficulty \(Z \leq z_i\) with certainty, but cannot solve any problem $Z>z_i$. We assume that there are two types of workers, who differ in their skill levels, denoted by $z_0<z_1$. We call individuals with skill level $z_0$ `juniors', and individuals with skill level $z_1$ `seniors'.  

\paragraph{Demographic structure.} We assume that time is continuous, and at any given point in time, $\delta L$ people are born. A fraction $\phi$ of them are born with senior skills $z_1$ , and fraction $1-\phi$ with junior skills, $z_0$. They each die with a Poisson arrival rate of $\delta$, independent of skill. The model allows for learning by juniors in some cases, meaning that their skill level changes to $z_1$ stochastically. 

\paragraph{Working solo.} Working on a problem requires time, committed before knowing the difficulty of the problem. One problem takes one unit of time to work on. (This is a normalization of units.) If a person is working alone on a problem (called `solo work'), they can solve it with probability $z_i$, so their expected output per unit of time is $z_i$. These values also pin down their solo productivity-based wage in a competitive market: working alone, a junior would earn \(w_0 = z_0\) per unit of time, and a senior would earn \(w_1 = z_1\).

\paragraph{Working in teams.} Now consider teamwork: a senior can collaborate with several juniors. The idea is that juniors attempt the problems first; they solve the easier ones that they are capable of, and escalate the unsolved harder problems up to the senior. The senior then spends time on handling those tougher problems. We assume that whenever a junior brings a problem to the senior, the senior spends \(h < 1\) units of time on it, whether or not the senior eventually manages to solve it (the difficulty is unknown until attempted). The parameter \(h\) captures the time cost per problem of communication, mentoring and solving the problem. Importantly, \(h<1\) reflects that it is more time-efficient for a senior to solve a problem brought by a junior than to pick up a random problem on their own. Intuitively, the junior filters and only forwards the harder subset of problems to seniors. There is a constraint on the senior's time, in expectation, they have to be able to handle all the problems that juniors send to them.

\subsection{Solution of baseline model} 

In our baseline model there is no learning, each individual spends their entire life with the skill they were born with. This is essentially a static model, where the measure of juniors in the economy is $L_0=(1-\phi)L$ and the measure of seniors is $L_1=\phi L$ at all times.

The time constraint of the senior pins down the measure of juniors they can work with, which we denote by $n_0$. As the probability that a single junior passes on the problem that they draw is $1-z_0$, the measure of total problems passed on is given by $n_0(1-z_0)$, which takes $hn_0(1-z_0)$ time for the senior. Since seniors also have 1 unit of time, this implies that the optimal team size is given by
\begin{align}\label{eq:team_size}
n_0=\frac{1}{h(1-z_0)}.
\end{align}
\paragraph{Team output.} Team output is the sum of problems that the juniors solve and of those that the senior solves. The probability that the senior can solve a problem escalated to them is $(z_1-z_0)/(1-z_0)$. So total team output is
\begin{align}\label{eq:teamq}
Q_{team} = n_0z_0+n_0(1-z_0)\frac{z_1-z_0}{1-z_0}=n_0z_1=\frac{z_1}{h(1-z_0)}.
\end{align}
The senior essentially `multiplies' their expertise across \(n_0\) juniors.\footnote{Thus the team output is simply the measure of problems encountered by the team ($n_0$) times the probability that the senior can solve a random problem ($z_1$).} This result highlights why seniors can be extremely productive when supported by a team of juniors: if communication is efficient (small \(h\)) and juniors only pass on the truly hard problems (small \(1-z_0\)), a senior can leverage a large team. Note that the marginal value of increasing the senior’s skill $z_1$ is amplified in a team relative to solo work as $1/h(1-z_0)>1$, which follows from our assumptions on $h$ and on $z_0$. \\
Team work is better than solo work if team output is higher than the sum of individual outputs ($n_0z_0+z_1$), which boils down to the following:
\begin{align}
%\notag
%n_0z_0+z_1 & <n_0z_0+n_0(1-z_0) \frac{z_1-z_0}{1-z_0} \\
%\notag
%z_1 & < \frac{z_1-z_0}{h(1-z_0)} \\
\label{eq:pc}\tag{PC}
\frac{1}{1-h(1-z_0)} & < \frac{z_1}{z_0}.
\end{align}
This requires the senior's productivity to be sufficiently large relative to the junior's productivity. By how much depends on the efficiency of teamwork. If teamwork is more efficient, i.e., $h$ is smaller and $z_0$ is larger, the senior's productivity does not have to be so large relative to the junior's for teamwork to be better than solo work. We refer to this condition as the participation constraint (the reason for this is described later), and we assume it holds.

\paragraph{Labor market equilibrium.} If teamwork is better than solo work, then given the supply of seniors, $L_1$, and juniors, $L_0$, as many teams form as possible. Wages for seniors, $w_1$ and for juniors $w_0$ are determined by supply and demand, depending on whether team opportunities are abundant or scarce.

As in teamwork each senior wants to head a team of $n_0$ juniors, two cases naturally arise. Either there are too many juniors (case 1) or too few juniors (case 2) relative to seniors.

\paragraph{Case 1: Too many juniors.}  This case arises if $L_0 > n_0 L_1$, that is even if every senior takes on a full team of $n_0$ juniors, there would still be some juniors left without a senior. In the model without learning this condition boils down to $\phi=\frac{L_1}{L}<\frac{h(1-z_0)}{1+h(1-z_0)}$. In this scenario, not all juniors can join teams, and the excess juniors must work solo. All juniors not in a team produce output on their own and earn their solo wage $w_0=z_0$. All juniors working in teams must also earn $w_0$; if they were offered less, they would choose to work on their own, and no senior would offer more, as any solo-working junior would join a team for wage $w_0+\varepsilon$. If juniors are abundant, then seniors extract all the surplus generated by teamwork. The senior's wage is team output, as given by equation \eqref{eq:teamq}, minus the wage cost of juniors:
\begin{align}\label{eq:w1}
w_1=Q_{team}-n_0w_0 = \frac{z_1-z_0}{h(1-z_0)}.
\end{align}
The seniors are happy to head teams if their wage from teamwork exceeds their wage from solo work, $z_1$. This implies a participation constraint that is equivalent to equation \eqref{eq:pc}. If output from teamwork is larger than the sum of the solo output of team members, then the senior who extracts all the rent is better off heading a team than working solo.

Wage inequality in this case is
\begin{align}\label{eq:ineq1}
\frac{w_1}{w_0} = \frac{z_1-z_0}{z_0h(1-z_0)},
\end{align} 
which exceeds wage inequality from solo work, $z_1/z_0$, as long as seniors are willing to lead teams, that is as long as the participation constraint, equation \eqref{eq:pc}, is satisfied. 

Output per capita in the economy is the sum of team output and solo output of all juniors who could not join a team divided by population
\begin{align}\label{eq:y1}
Y_{base1} = \frac{L_1}{L}Q_{team}+\frac{L_0-L_1n_0}{L}z_0=(1-\phi)z_0+\phi\frac{z_1-z_0}{h(1-z_0)}.
\end{align}
This exceeds autarky GDP, i.e., output per capita if everyone works solo, given by $Y_{solo} = (1-\phi)z_0+\phi z_1$ if the participation constraint in \eqref{eq:pc} is satisfied.


\paragraph{Case 2: Juniors are scarce.} This case arises if $L_0 \leq n_0 L_1$, which means that there are not enough juniors to utilize all seniors' capacity. In this case every junior joins a team, and some seniors will be left without any junior partners. Juniors become the scarce factor, and seniors are abundant. Seniors who fail to hire a
junior would have to work alone and earn $w_1=z_1$. This implies that also those seniors who work in teams will earn the same wage, and juniors capture all the surplus generated in teamwork. Each junior's wage in this case is their share of output minus the senior's wage:
\begin{align}\label{eq:w0}
w_0 = \frac{Q_{team}-z_1}{n_0}=\frac{\frac{z_1}{h(1-z_0)}-z_1}{\frac{1}{h(1-z_0)}}=z_1[1-h(1-z_0)].
\end{align}
Juniors are willing to be part of a team if their wage in teams exceeds their solo wage, $w_0>z_0$. This participation constraint is satisfied if equation \eqref{eq:pc} holds, that is if team output is higher than the sum of individual outputs. Junior wages will be higher if teamwork is more efficient, i.e.\ if $h$ is small and if $z_0$ is large. Wage inequality in this case is
\begin{align}\label{eq:ineq2}
\frac{w_1}{w_0} = \frac{z_1}{z_1[1-h(1-z_0)]}=\frac{1}{1-h(1-z_0)},
\end{align}
which is below wage inequality from solo work, $z_1/z_0$, as long as juniors are willing to participate in teams, that is the participation constraint in equation \eqref{eq:pc} is satisfied. Note that $w_1>w_0$ even in this case, so seniors prefer to work either solo or as team leaders, rather than joining a team as a junior.

Output per worker in case 2 is given by the measure of teams $L_0/n_0$ times team output, plus the measure of seniors working solo times $z_1$ divided by population:  
\begin{align}
Y_{base2} = \frac{L_0/n_0}{L}Q_{team}+\frac{L_1-L_0/n_0}{L}z_1=[1-(1-\phi)h(1-z_0)]z_1.
\end{align}

%Intuitively, when juniors are scarce, even a very high-skill senior cannot command a huge premium because they desperately need juniors to leverage their skill. Juniors then receive a large share of the value (they ``capture the rent'' from the teamwork). By contrast, in senior-scarce scenario, the senior could name their price since juniors had nowhere else to get the premium.

In summary, our baseline static model yields two distinct regimes for wage inequality. In case 1, when there are too many juniors, seniors capture most of the surplus and inequality is high. In case 2, when there are too many seniors, juniors get a larger share of the surplus, compressing the wage gap. This has interesting implications: for example, if an economy suddenly increases the supply of seniors (say through education or immigration of
skilled workers), it could flip from case 1 to case 2, potentially reducing wage inequality. Conversely, an influx of junior workers without enough senior mentors could increase inequality.

We can also analyze how technological changes affect inequality. For instance, improvements in communication technology (a lower \(h\)) make teams more efficient. In case 1, a reduction in \(h\) increases \(w_1/w_0\) because it amplifies the senior's leverage (see \eqref{eq:ineq1}). In case 2, inequality actually decreases as \(h\)
falls (see \eqref{eq:ineq2}). Thus, if better IT reduces mentoring time \(h\), the effect on inequality is ambiguous: if
seniors are scarce (case 1), inequality rises; if juniors are scarce (case 2), inequality falls. %This observation foreshadows what could happen with AI, which can be seen as an extreme improvement in `communication' productivity (or even a replacement for juniors).

Other interesting comparative statics are with respect to the skill level of juniors and seniors. An increase in the juniors' skill level \(z_0\) (e.g.\ better basic education for all workers) reduces wage inequality in both cases (see \eqref{eq:ineq1} and \eqref{eq:ineq2}). The intuition is that if juniors become more capable, the senior's relative advantage shrinks, and juniors also solve more tasks themselves, making seniors slightly less important. An increase in the seniors' skill level $z_1$ increases wage inequality in case 1, but does not impact wage inequality in case 2. 

In what follows our analysis will consider economies in case 1, where juniors are abundant. 

%{(These insights are qualitatively in line with broader labor literature: technologies that complement high-skill workers can increase inequality if high-skill workers are scarce, but if lower-skill workers improve their capabilities, the gap narrows.)}

\subsection{Introducing AI as a team member}\label{introducing-ai-as-a-team-member}

We now extend the model to include AI as a potential `worker' in the team. We consider an AI system that functions similarly to a junior: it attempts to solve all problems, it can solve problems up to a certain difficulty, $z_A$, and it passes on the rest. Thus, $z_A$ for AI is similar to the junior's skill $z_0$. Let $h_A$ denote the communication time per problem between the AI and the senior. This represents the time a senior must spend to review or integrate the AI's output on tasks the AI couldn't fully resolve. Perhaps surprisingly, working with an AI might involve some overhead (interpreting AI suggestions, correcting errors). We assume \(h_A\) plays a similar role to \(h\) for human juniors, and likely \(h_A \in (0,1)\), implying that AI can also save time, but does not eliminate oversight entirely.

The key difference between employing juniors or using AI is in costs: hiring an AI has essentially no wage cost. AI is like a machine -- we can assume it is a fixed asset or its `salary' is zero for the marginal analysis. Thus, a senior who has access to AI can use as many `AI juniors'  -- or send as many problems to the AI -- as they want, limited only by the senior's time.

Suppose a senior can choose to work with {\(n_A\) units of AI (multiple AI instances or simply scaling usage). Similarly to before, if the senior allocates all their time to handling the AI's unsolved problems, then \(n_A (1 - z_A) h_A = 1,\) implying \(n_A = \frac{1}{h_A(1-z_A)}.\) This mirrors \eqref{eq:team_size}. Essentially, a single senior can now leverage up to \(1/[h_A(1-z_A)]\) AI processes in parallel. The output per senior with AI would be: 
\begin{align}\label{eq:aiq}
Q_{AI} = n_A z_A + n_A (1-z_A)\frac{z_1-z_A}{1-z_A} = n_A z_1 = \frac{z_1}{h_A(1-z_A)}.
\end{align}
Comparing this to $Q_{team}$ in \eqref{eq:teamq}, we see that the structure is analogous. If \(z_A\) and \(h_A\) are comparable to a junior's $z_0$ and $h$, then AI can similarly boost the senior's productivity. Importantly, however, the AI does not demand a wage or have an outside option. This can fundamentally alter the equilibrium.

Consider an economy initially in case 1, with too many juniors relative to seniors. In the absence of AI, seniors were teaming up with juniors and paying them $w_0 = z_0$. Now introduce a capable AI. A senior could choose to replace human juniors with AI if it is beneficial. The senior's decision depends on whether their return is higher when using AI (they get the entire output) or when employing juniors, in which case they get $w_1$ as given by \eqref{eq:w1}. Comparing the senior's earnings in the two cases, they will choose to use AI if:
\begin{align}\notag
\frac{z_1}{h_A(1-z_A)} > \frac{z_1-z_0}{h(1-z_0)} \\
\label{eq:AIuse}
\frac{h(1-z_0)}{h_A(1-z_A)} > 1- \frac{z_0}{z_1}. 
\end{align}
This condition says that the relative efficiency of AI (the LHS is basically how many more tasks a senior can handle with AI vs with a junior) exceeds a threshold related to the junior's contribution (the RHS is the fraction of solved tasks that juniors cannot solve). If AI is equally capable as juniors (\(z_A = z_0\)) and equally easy to work with (\(h_A = h\)), then the LHS of \eqref{eq:AIuse} simplifies to 1, and the RHS is \(1 - \frac{z_0}{z_1}\). Since \(z_1 > z_0>0\), the RHS is less than one and so \eqref{eq:AIuse} holds automatically. This means that even if AI had the same skill and communication cost as a junior, a senior would still prefer AI, because with AI they do not have to share the output with anyone. Essentially, as long as seniors have to pay juniors at least something (and in case 1 they pay juniors their outside option \(z_0\)), an equivalent AI is more attractive due to zero wage. The senior `saves' the junior wage cost and keeps the full surplus.

%Thus, if AI can do a comparable job to a junior, seniors will tend to replace juniors with AI. 
Condition \eqref{eq:AIuse} can also be satisfied even if seniors are relatively less productive using AI, i.e.\ $h_A(1-z_A)>h(1-z_0)$, their earnings can still be higher as they do not need to share output with juniors. 

Under condition \eqref{eq:AIuse}, a senior's optimal choice is to employ AI exclusively and hire zero juniors. In equilibrium all juniors are effectively pushed out of teams. Juniors revert to working solo on problems generating output and income \(z_0\) each. Each senior now works with AI and produces output \(\frac{z_1}{h_A(1-z_A)}\), and receives all of it as wage. %The senior's wage would adjust to reflect their new productivity (if seniors are still scarce, they capture it; if seniors became abundant relative to remaining team opportunities, wages might equalize differently, but presumably if all seniors adopt AI, juniors are no longer a limiting factor at all).
Output per capita in the economy is given by
\begin{align}\label{eq:yAI}
Y_{AI} = \frac{L_1}{L}Q_{AI}+\frac{L_0}{L}z_0=(1-\phi)z_0+\phi\frac{z_1}{h_A(1-z_A)}.
\end{align}
Output per capita in \eqref{eq:yAI} is larger than without AI given in \eqref{eq:y1} whenever it is beneficial for seniors to adopt AI instead of working with juniors. Introducing AI in this way thus unambiguously raises GDP. Thus, in a static sense, AI raises efficiency -- no surprise there. We get more output because seniors can handle more problems with the help of AI, and juniors do what they can on their own.

In the new equilibrium wage inequality is given by
\begin{displaymath}
\frac{w_1}{w_0} = \frac{z_1}{z_0h_A(1-z_A)},
\end{displaymath}
as all juniors are essentially relegated to solo work, earning \(w_0 = z_0\), and seniors get all the rents from working with AI, \(w_1 = \frac{z_1}{h_A(1-z_A)}\). This is larger than the original level of inequality given in \eqref{eq:ineq1} as long as it is beneficial to use AI, that is \eqref{eq:AIuse} holds. If AI replaces juniors, inequality increases: seniors' productivity and pay goes up, while juniors remain at low-productivity solo work earning \(z_0\).

%However, static efficiency is not our sole interest. {The worry is about dynamics: what happens over time if juniors never work with seniors?} Juniors working solo do not learn from a mentor, potentially stunting the creation of future seniors. The next section incorporates this learning aspect.

% Before moving on, we briefly consider: {What if juniors also have access to AI?} So far, we assumed juniors couldn't use AI, which is why they became redundant. But suppose juniors too could utilize AI tools in their solo work. In reality, tools like ChatGPT or Copilot {augment even relatively inexperienced workers}, helping them perform above their usual skill level. If a junior with AI could effectively achieve a higher skill (say solve problems up to difficulty \(z_0'\) where \(z_0' > z_0\)), it might reduce the gap with seniors. It might allow one junior+AI to handle tasks that previously required escalation to a senior. This scenario could {change senior behavior}: instead of entirely displacing juniors, seniors might still employ a smaller number of juniors who are each more productive thanks to AI assistance. The model would then treat the junior+AI bundle as having a higher effective \(z_0'\) or lower effective time \(h\) needed. We won't formally analyze this case here, but we note that {AI as a complement (augmenting juniors)} has very different implications than AI as a pure substitute. Indeed, recent empirical evidence suggests generative AI can {help junior or less-skilled workers improve faster}, by disseminating best practices and providing guidance. For instance, customer support agents with AI assistance saw novices catch up to experienced workers more quickly, moving ``down the experience curve'' faster. If juniors could similarly learn faster with AI, then the dynamic loss might be mitigated. The worst dynamic outcome arises when AI is {used instead of training juniors}, not when it's used to support juniors. We return to this point in the conclusion.

\subsection{Dynamic considerations: Learning by mentoring}\label{sec:learning}

Thus far, we treated the supply of seniors and juniors as fixed. We now enrich the model with a simple dynamic mechanism: juniors can learn and become seniors over time by working in teams (being mentored). This captures the idea of a career progression or on-the-job learning: a junior who spends time collaborating with a senior gradually acquires the senior-level skill. We model this as a Poisson process: while working in a team under a senior, a junior `graduates' to senior skill level at an instant rate \(\lambda\). %This could be thought of as the junior accumulating enough knowledge to handle the hardest problems, thus effectively reaching skill \(z_1\). We assume if this happens, the person is now a senior (skill \(z_1\)) from that point on. 

%People are born at rate \(\delta L\), so \(\delta\) is birth rate relative to population, and die at rate \(\delta\), thus ensuring a stationary population \(L\). A fraction \(\phi\) of new entrants are exogenously high-skill and start as seniors, while the rest \(1-\phi\) start as juniors. Without any on-the-job learning, the economy's fraction of seniors would just be \(\phi\) in steady state. However, with learning by mentoring, additional seniors are created from juniors' working in teams in each instant.

The stock of seniors \(L_1\) evolves according to 
\begin{align*}
\dot{L_1} = \phi\delta L -\delta L_1 +\lambda \min\{L_1n_0,L_0\},
\end{align*}
where $\phi \delta L$ is the measure of individuals born with senior skills, $\delta L_1$ seniors exit due to death, and $\lambda \min\{L_1n_0,L_0\}$ juniors become seniors. The $\min\{L_1n_0,L_0\}$ is equal to $L_1n_0$ in case 1 when seniors are scarce and determine the measure of juniors working in teams, and is equal to $L_0$ in case 2 when there are too many seniors, and all juniors work in teams. Let's consider a steady state of this system ($L_1$ constant) under the assumption that the economy starts and remains in case 1, i.e.\ seniors are always scarce. The steady state share of seniors is given by
\begin{align}\label{eq:senshare}
\frac{L_1}{L} = \frac{\phi}{1-\frac{\lambda}{\delta} \frac{1}{h(1-z_0)}}.
\end{align}
This is the steady-state share of seniors when there is learning. This fraction has to be between $0$ and $1$. As long as \(\frac{\lambda}{\delta} < h(1-z_0)\), this fraction is positive. Learning has to be sufficiently slow relative to exit, $\frac{\lambda}{\delta} < (1-\phi)h(1-z_0)$, for it to be also smaller than one, so that not everyone ends up a senior. To ensure that the economy remains in case 1, that is seniors remain scarce despite learning, the steady state share of seniors has to be smaller than $\frac{h(1-z_0)}{1+h(1-z_0)}$. This puts an even more stringent limit on the speed of learning:  $\frac{\lambda}{\delta} < (1-\phi)h(1-z_0)-\phi$. 

Not surprisingly, learning by mentoring raises the long-run proportion of high-skill workers as can be verified from \eqref{eq:senshare} $\frac{L_1}{L} > \phi$. This is a positive externality of teamwork: it increases the economy's human capital over time. The faster the learning rate \(\lambda\) or the larger the teams (higher \(n_0\)), the greater the boost to \(L_1/L\). If \(\lambda \to 0\), we recover \(L_1/L = \phi\), and as \(\lambda\) increases, \(L_1/L\) can be substantially above \(\phi\).

Team output, junior and senior wages are all the same as in the model without learning. The steady-state output per capita with learning is given by  
\begin{align}\label{eq:ylearn}
Y_{learning, steady} = \frac{L_1}{L} \frac{z_1-z_0}{h(1-z_0)} + \frac{L_0}{L} z_0=%\frac{\phi}{1-\frac{\lambda}{\delta} \frac{1}{h(1-z_0)}}\frac{z_1 - z_0}{h(1-z_0)}+\left[1-\frac{\phi}{1-\frac{\lambda}{\delta} \frac{1}{h(1-z_0)}}\right]z_0.
\phi \frac{z_1 - z_0}{h(1-z_0) - \frac{\lambda}{\delta}}+\left[1-\phi\frac{h(1-z_0)}{h(1-z_0) - \frac{\lambda}{\delta}}\right]z_0.
\end{align}
%After some algebra, this simplifies to: 
%\begin{align}\label{eq:ylearn}
%Y_{learning, steady} = \phi \frac{z_1 - z_0}{h(1-z_0) - \frac{\lambda}{\delta}}+\left[1-\phi\frac{h(1-z_0)}{h(1-z_0) - \frac{\lambda}{\delta}}\right]z_0.
%\end{align}
It is easy to see that steady state output per worker is increasing in the speed of learning, $\lambda$, because more workers end up as high-skill. In the limit of no learning, $\lambda=0$, \eqref{eq:ylearn} simplifies to
$(1-\phi)z_0 + \phi\frac{z_1 - z_0}{h(1-z_0)}$, which corresponds to output per capita without learning given in \eqref{eq:y1}.

\subsection{AI in the dynamic model with learning}

Now imagine that the economy with learning is at its steady state, when AI technology arrives. If it is worth it for seniors to use AI, that is condition \eqref{eq:AIuse}, repeated below, is satisfied 
\begin{align*}
\frac{h(1-z_0)}{h_A(1-z_A)} > 1- \frac{z_0}{z_1},
\end{align*}
then all seniors use AI, no juniors work in teams, and hence no on-the-job learning occurs. At this point, the output of seniors increases, as well as overall GDP per capita. Hence AI is introduced only if it yields a static gain, holding the share of seniors and juniors constant. However, the fraction of seniors starts to fall (as a larger measure is dying than is born), until it reaches $\phi$, its steady state without learning. Therefore, \(L_1/L = \phi\) in the long run with AI and learning, as AI adoption eliminates the mentoring pathway. GDP per capita in the steady state is equal to that in the economy without learning and with AI as in \eqref{eq:yAI}, repeated below:
\begin{align*}
Y_{AI} = \frac{L_1}{L}Q_{AI}+\frac{L_0}{L}z_0=(1-\phi)z_0+\phi\frac{z_1}{h_A(1-z_A)}.
\end{align*}

The crucial question is which steady state yields higher output, with or without AI? This is not obvious because AI boosts the current productivity of seniors, but eliminates the learning that boosts future human capital. If learning effects are small (either \(\lambda\) low or \(z_1 - z_0\) not too large), long run output with AI may dominate. But if learning effects are powerful, losing them can outweigh AI's static gain in the long run.

Comparing $Y_{AI}$ (from \eqref{eq:yAI}) and $Y_{learning,steady}$ (from \eqref{eq:ylearn}) we can derive a condition for AI to reduce long-run GDP per capita:
\begin{align}\label{eq:ineffAI}
\frac{\lambda}{\delta}>\frac{z_1\frac{h(1-z_0)}{h_A(1-z_A)}-(z_1-z_0)}{\frac{z_1}{h_A(1-z_A)}-z_0}.
\end{align}

%\begin{equation}
%\frac{z_1}{h_A(1-z_A)} - z_0 <
%\frac{z_1 - z_0}{h(1-z_0) - \frac{\lambda}{\delta}} -
%\frac{z_0}{1 - \frac{\lambda}{\delta h(1-z_0)}}. \tag{13}
%\end{equation}
%This expression basically asks whether the {AI-driven senior output advantage} (\(\frac{z_1}{h_A(1-z_A)} - z_0\), i.e.~how much more a senior+AI produces over a junior's output) is smaller than the {mentoring-driven output advantage} (the right-hand side is roughly the additional output per capita gained from having more seniors via learning). If the learning term is large (high \(\lambda\)), the inequality can hold even if AI has a strong static benefit.

%To give intuition: if \(\lambda = 0\) (no learning), the RHS of (13) reduces to \(\frac{z_1 - z_0}{h(1-z_0)} - z_0\), which is exactly $ \frac{z_1}{h(1-z_0)} - (z_0 + \frac{z_1 - z_0}{h(1-z_0)}) = \frac{z_1}{h(1-z_0)} - \frac{z_1}{h(1-z_0)} = 0$. So the inequality says AI decreases output if $ \frac{z_1}{h_A(1-z_A)} - z_0 <{} 0$, which would {never} be true if \(z_1 > z_0\). So with \(\lambda=0\), AI always helps or at least doesn't hurt output (as expected). As \(\lambda\) grows, the RHS increases, eventually possibly exceeding the LHS.
This condition requires the speed of learning to be sufficiently large relative to productivity gains from AI.\footnote{The numerator on the right hand side is positive if \eqref{eq:AIuse} is satisfied and AI is implemented, the denominator is always positive.} The right hand side is increasing in the productivity of an AI enhanced senior ($z_1/(h_A(1-z_A))$) and in the skill of juniors, while it is decreasing in the efficiency of teamwork ($1/(h(1-z_0))$) and in the skill difference between seniors and juniors. These results are all intuitive. The larger the productivity of an AI enhanced senior, the faster learning has to be to offset AI induced productivity gains. The higher is the skill of juniors, the better is the outside option for them when AI is adopted, and the smaller the economy's GDP loss from moving from teamwork to solo work. On the other hand, the more efficient teamwork is, the higher is GDP in the teamwork and no AI economy, and so learning does not have to be that fast for AI to generate dynamic losses. Similarly, the larger the skill gain from becoming a senior is, a lower learning speed can also lead to dynamic losses from AI. Note that the speed of learning cannot be too large either, otherwise eventually there would be too many seniors. 



If this condition is satisfied, then the dynamic losses from the lack of learning outweigh the static gains from AI. This highlights a potential dynamic inefficiency: seniors may adopt AI because it is privately optimal, as it yields higher earnings for them, but collectively this might lead to lower output in the long run due to the collapse of human capital formation. 


\textcolor{green!60!black}{There is a parallel here to the idea of excessive automation, i.e., that firms adopt labor-saving technology beyond the socially optimal level because they do not internalize the loss of future skilled workers or the broader consequences on the labor market (Acemoglu \& Restrepo, 2020; Korinek, 2023). Our model provides a microfoundation for one such consequence, foregone learning-by-mentoring. \\
It is worth mentioning that our analysis is somewhat one-sided in that {we did not allow AI itself to improve} over time in this model. In reality, AI could also become more capable by learning from data (including data generated by humans). Some theorists describe advanced AI as having a ``learning-by-using'' dynamic -- the more it's used, the
more it learns from human decisions, potentially {accelerating} its capability growth. A recent NBER paper conceptualizes AI in this way and warns that AI might initially complement workers but eventually substitute them as the AI becomes very skilled. That dynamic is different from ours (where humans learn, not AI), but it also leads to
time-varying impacts on labor. In their model, wages might rise initially and then fall as AI crosses a certain threshold. In our model, wages for juniors might rise initially (if juniors are scarce) but then collapse if AI adoption becomes ubiquitous and no new seniors emerge.} 

\subsection{Internalized gains from learning and AI}

We have so far assumed that juniors do not internalize the future benefit of learning when deciding on jobs. What if they anticipate the career progression and are willing to accept lower current wages for a chance to become seniors? This introduces an interesting twist: juniors might essentially `pay for' their training by working at a lower wage in teams than what they would earn solo. In a competitive labor market with forward-looking workers and where juniors are abundant, the junior's expected lifetime utility from a team position should equal that from working solo. Let $J_{0,team}$ denote the expected present value of being a junior in a team, given by the following Bellman equation:
\begin{align*}
\delta J_{0,team} = w_{0,team} + \lambda \left[\frac{w_{1,team}}{\delta} - J_{0,team}\right],
\end{align*}
where $\frac{w_{1,team}}{\delta}$ is the present value of a senior earning $w_{1,team}$ per period until death. We can express $J_{0,team}$ as
\begin{align*}
J_{0,team} = \frac{w_{0,\text{team}} + \lambda \frac{w_{1,team}}{\delta}}{\delta + \lambda},
\end{align*}
The value of being a solo junior is $J_{0,solo} = \frac{z_0}{\delta}$, as solo juniors don't learn and earn $z_0$ until death. As there is an abundance of juniors, they need to be indifferent between the two options, $J_{0,team} = J_{0,solo}$, which implies:
\begin{equation}
w_{0,team} = z_0 - \frac{\lambda}{\delta}(w_{1,team} - z_0). 
\end{equation}
This means that juniors in a team accept a wage below their solo marginal product $z_0$, because they expect to recoup it when they become seniors.\footnote{To see that $w_{0,team}<z_0$, note that $\lambda>0$, and $w_{1,team}>z_0$, because for seniors to participate $w_{1,team}>z_1>z_0$.} In other words, they effectively pay the senior (or firm) for training via a wage discount. If juniors are confident in promotion, such an equilibrium could occur. It resembles classic `apprenticeship' where trainees work for low pay to gain skills.

The senior's surplus from a team when juniors internalize gains from learning is even larger because juniors wages are lower. The senior's wage is determined as
\begin{align*}
w_{1,team}=n_0(z_1-w_{0,team})=\frac{z_1-w_{0,team}}{h(1-z_0)}.
\end{align*}
Using the expression for $w_{0,team}$ and re-arranging we get that
\begin{align*}
%w_{1,team} &= \frac{z_1-z_0 + \frac{\lambda}{\delta}(w_{1,team} - z_0)}{h(1-z_0)} \\
w_{1,team} &= \frac{z_1-z_0(1+\frac{\lambda}{\delta})}{h(1-z_0)(1-\frac{\lambda}{\delta}\frac{1}{h(1-z_0)})}=\frac{z_1-z_0(1+\frac{\lambda}{\delta})}{h(1-z_0)-\frac{\lambda}{\delta}}.
\end{align*}
This is the senior wage when juniors fully internalize learning. If there is no learning ($\lambda=0$) then this is equal to the senior wage in case 1 of the baseline model. It is straightforward to check that $w_{1,team}$ is increasing in the speed of learning, $\lambda/\delta$, and is larger than the senior wage when juniors do not internalize learning.\footnote{Take the partial derivative of $w_{1,team}$ with respect to $\lambda/\delta$ and note that if \eqref{eq:pc} is satisfied, then the derivative is positive.} This is intuitive, as when juniors internalize learning, they accept lower wages than $z_0$, and hence the senior retains more of the same team output.

Wage inequality is higher in this economy than in the economy without (internalized) learning, as the lowest paid workers earn less than $z_0$, while the highest paid workers earn more than $(z_1-z_0)/(h(1-z_0))$.  

The fact that senior wages are higher with internalized learning means that the requirement on the productivity of AI is more stringent. The condition for AI use becomes 
\begin{align*}
\frac{z_1-z_0(1+\frac{\lambda}{\delta})}{h(1-z_0)-\frac{\lambda}{\delta}} < \frac{z_1}{h_A(1-z_A)}.
\end{align*}
The key insight is that if juniors value learning, they effectively subsidize the team, making seniors less eager to drop them for AI. In fact, seniors might stick with human teams even when AI is somewhat better, as long as the
juniors' wage is depressed enough that the senior's net payoff is comparable. 
%This hints at a kind of {rent-seeking behavior}: an incumbent senior might resist a labor-saving technology (AI) not because it's bad for productivity, but because adopting it would break the cycle that allows them to capture rents from the next generation. This is reminiscent of scenarios in industrial organization where incumbents deter entry or new technology to preserve future monopoly rents. In our labor context, the senior might forego an immediate productivity gain from AI in order to continue benefiting from cheap junior labor and possibly a share in their future success (if there's some way seniors benefit from having trained successors -- e.g., in a firm hierarchy or partnership model). This particular strategic angle goes beyond our basic model, but it's an intriguing possibility for extension.

Team output and the long run share of seniors are the same as in the economy with learning that is not internalized, and hence GDP is also the same. The condition for the dynamic inefficiency of AI is therefore the same as before, given in \eqref{eq:ineffAI} and repeated here:
\begin{align*}
\frac{\lambda}{\delta}>\frac{z_1\frac{h(1-z_0)}{h_A(1-z_A)}-(z_1-z_0)}{\frac{z_1}{h_A(1-z_A)}-z_0}.
\end{align*}
As $z_1/(h_A(1-z_A))$ needs to be larger for AI to be implemented, the right hand side of the above expression will be higher, implying a ceteris paribus that the above inequality is less likely to hold. While internalized learning makes dynamically inefficient AI less likely to happen, it is still a possibility. 


\subsection{Discussion: Related Literature and Policy
Implications}\label{discussion-related-literature-and-policy-implications}

Our model highlights a {dynamic externality} in the adoption of
AI in skilled work: the loss of learning opportunities for junior
workers. This connects to several strands of literature:

{Learning-by-doing and dynamic inefficiencies:} The idea that
current production can build future human capital has a long history
in economics (Arrow, 1962; Lucas, 1988). In those models, firms or
workers do not fully internalize the benefit of the skills they
accumulate for society's future, leading to underinvestment in
learning. In our setup, the externality is explicit: when a senior
chooses AI over mentoring a junior, the senior ignores the fact that
one less junior will become a high-skill worker. This is a social loss
not reflected in the senior's private payoff. Our results echo themes
in Acemoglu's work on automation: he argues that there can be
{excessive automation} because firms adopt cost-saving
technologies without considering the negative effect on workers' skill
acquisition and earnings. Acemoglu \& Restrepo (2018, 2020) emphasize
that automation needs to be counterbalanced by new tasks for labor;
otherwise, workers get displaced and aggregate gains may be smaller
than anticipated. In our model, training juniors can be viewed as
creating ``new skilled workers'' (akin to new task opportunities for
labor in the future). If AI halts that, the long-run supply of skilled
labor is lower, potentially reducing innovation or productivity down
the line.

{Rent-seeking and optimal incentives:} We drew a parallel to an
insight by Buera and co-authors (2025). They study dynamic competition
in oligopolies and find that private incentives can deviate from
social optima due to dynamic considerations (firms do not internalize
the full social benefit of more competition or innovation). However,
they also show that {dynamic competition alone doesn't always
justify intervention} -- in some cases the equilibrium can be
constrained-efficient. The analogy in our context would be: is the
private outcome (seniors replacing juniors with AI) inefficient, or
could it be constrained-efficient? If seniors are scarce and capture
rents, they undervalue the creation of new seniors (since that would
erode their future rents). This likely leads to {under-provision
of training} relative to the social optimum. Even if seniors
internalize juniors' learning (via lower wages), the senior is just
extracting that value; the junior's presence still creates a positive
externality for others (e.g., future firms or the economy benefit from
having more skilled workers beyond the senior's own firm). Thus, we
suspect the market equilibrium is tilted toward too much AI adoption
from a social viewpoint, whenever learning externalities are
significant. This is a form of dynamic inefficiency where regulators
or policy might want to intervene -- akin to subsidizing training or
taxing automation. Buera et al.'s framework is different (firms and
innovation), but the common theme is balancing static gains with
dynamic considerations. In Buera's model, the government might
subsidize entrants to maintain competition; in our model, one could
imagine {incentives for firms to hire and train juniors} even
if AI is available, to sustain human capital formation.

{Evidence on AI's impact on training and skills:} Given that
generative AI is a very recent technology, hard empirical evidence on
long-run skill dynamics is limited. However, early studies and surveys
provide hints:

As noted earlier, Hess et al.~(2023) find that in jobs with high
automation risk, {workers and firms invest less in training}.
This aligns with our model's implication that firms might cut back
on developing junior talent if they plan to automate roles.
Muehlemann (2024) finds that {AI adoption in German firms led
to reduced training for current workers, but an increase in
apprenticeship contracts}. The latter suggests some firms anticipate
needing skilled workers who know how to work with AI, so they ramp
up apprentice programs. In our terms, that would be like trying to
ensure juniors are still coming up the pipeline, perhaps in a more
AI-centric way.

There is anecdotal evidence of companies {reducing
entry-level hiring} because of AI. For example, some law firms have
slowed hiring of junior lawyers as AI can do first drafts of
contracts and research. In programming, one hears quotes like
{``why hire juniors when a single senior with AI can do the
job?''}. Our model formalizes the logic behind such quotes. But
commentators warn that this is short-sighted: junior roles today are
how seniors of tomorrow are created.

On the flip side, AI tools might serve as a {training device}.
The study by Brynjolfsson et al.~(2023) provides
{``proof-of-concept'' that generative AI can supplement human
learning}: in customer support, novice workers improved markedly
with AI help, essentially learning from AI's suggestions. Noy and
Zhang (2023) found less-skilled writers improved their writing
quality using ChatGPT, closing some gap with more-skilled writers.
These findings suggest a possible {complementary} path: instead
of replacing juniors, firms could give juniors AI tools to make them
productive and accelerate their learning. In our model's terms, that
would keep \(\lambda\) (learning) alive while also enjoying some of
AI's static benefits -- a potential win-win if done right.

{Policy responses:} If indeed there is a danger that the
pipeline of skill formation gets broken, what policies could mitigate
this? One idea is {incentivizing human-complementary uses of
AI} over pure automation. Acemoglu et al.~(2023) argue for directing
innovation towards augmenting workers rather than replacing them.
Concretely, they suggest measures like:

Adjusting the {tax code}: currently, in the U.S., companies
can often save costs by investing in software/AI (capital) rather
than hiring workers, due to how labor is taxed (payroll taxes,
etc.). Making taxes neutral between hiring a person and deploying an
AI could remove an artificial incentive to cut jobs. Equivalently,
one could offer tax credits for training expenses or for maintaining
apprentice programs. If firms faced the true long-run cost of lost
human capital, they might choose a more balanced approach.

{Training subsidies or requirements}: Governments could
subsidize firms that provide robust training to young workers, or
even mandate industries (like law, medicine) to maintain certain
residency/internship positions. Historically, some professions have
{guild-like systems} to ensure knowledge transfer. In an AI
era, we might need updated versions of these to ensure juniors still
get experience, perhaps focusing on tasks AI can't do (or overseeing
AI).

{Worker voice and bargaining}: The CEPR columnsuggests that
giving workers more voice in tech implementation decisions could
help steer AI adoption in a worker-friendly direction. If junior
employees (or their unions) had a say, they might push for AI that
{helps them} rather than replaces them, or for maintaining
pathways to advancement. This is of course challenging if the
juniors are never hired to begin with -- a catch-22 -- but it speaks
to the need for broader stakeholder involvement.

{Ensuring new task creation}: In the long run, entirely new
roles might emerge that juniors can fill and learn in, even if old
entry-level tasks are done by AI. For example, if AI handles coding,
perhaps {prompt engineering} or {AI supervision} becomes
the entry role. Some optimists believe AI will create more demand
for human judgment and soft skills, which could form the basis of
new junior positions. Our model does not incorporate new task
creation, but if we did, it could alleviate the dynamic loss
(Acemoglu \& Restrepo (2019) stress that new tasks for humans
historically accompanied automation). There may be a need for
{policies that encourage the development of new complementary
jobs} -- e.g., funding for R\&D in areas where humans can expand
work with AI rather than be replaced.

{Long-term distributional effects:} Our model has implications
for inequality that resonate with ongoing debates. In the short run,
AI may increase the productivity of top-skilled workers (seniors),
increasing the wage gap if they capture that value. Indeed,
{inequality could rise sharply} if AI is used in the Case 1
scenario. Acemoglu's recent paper (2024) suggests that even if AI
makes lower-skilled workers more productive in some tasks, it might
{still} increase inequality unless it's creating whole new
opportunities. Our model's Case 1 outcome with AI is an example:
juniors might improve a bit with AI, but if they're largely sidelined,
the gap widens. However, if juniors are scarce (Case 2), they could
benefit and inequality could decrease, at least initially. Over the
long run, if the supply of skilled workers doesn't grow (or even
shrinks relative to population because of no learning), we could see a
form of {skill premium persistence} or even a decline in
overall innovation. There is also a parallel to the literature on
{human capital and growth}: if one generation doesn't pass on
skills to the next, you can get stagnation. This is somewhat analogous
to some low-development traps where lack of skill transfer keeps
productivity low.

In terms of {empirics}, this is a nascent area. It will be
interesting to see in a decade whether industries that heavily adopted
AI early (like perhaps software coding or customer service) have a
missing cohort of mid-level professionals. Will companies regret not
training people? Or will AI evolve so rapidly that many traditional
senior roles themselves change or become obsolete, making the old
``pyramid model'' of organization unnecessary? Some have speculated
about a future with {very flat organizations}: a few
super-experts (plus AI) do all the work, and everyone else finds other
things to do. Others argue that human oversight and creativity will
remain in demand, preserving the need for career progression.

\subsection{Conclusion}\label{conclusion}

We developed a stylized model of an economy with high-skill ``seniors''
and low-skill ``juniors'' to investigate the impact of AI on
productivity and skill formation. The model yields several insights.
{First}, in a static setting, teams of juniors and seniors are
highly productive, and the division of surplus depends on their relative
supply. Seniors capture most gains when they are scarce, but if juniors
are scarce, they can command higher wages. {Second}, AI can act
like a super-efficient junior (requiring less time \(h_A\) and possibly
having higher skill \(z_A\)), which makes it privately optimal for
seniors to replace human juniors in many cases. This raises short-run
output and can either increase or decrease wage inequality depending on
the labor supply situation -- though a likely outcome is increased
inequality with seniors earning much more. {Third}, and most
importantly, the removal of juniors from teams means the {loss of
a key learning channel}. In our dynamic extension, junior-senior teams
were the engine of creating new skilled workers (future seniors). If AI
displaces this, the economy could suffer a {lower steady-state
level of human capital and output}, despite the initial AI-induced
boost. We derived conditions under which long-run GDP per capita falls
with AI, even though short-run GDP rises.

These findings underscore a potential {trade-off between present
and future productivity}. Our model is admittedly abstract -- reality is
more complex, with many tasks and continuous skill development -- but it
captures the essence of a concern raised by practitioners: {``Where
will the experts of tomorrow come from if nobody hires juniors
today?''}. The model also resonates with historical anecdotes. For
instance, in professions like crafts or medicine, when training
pipelines broke down, it led to skill shortages until corrective
measures were taken (sometimes through public intervention). We might be
at risk of a similar phenomenon in modern knowledge industries with
generative AI.

We should note some {limitations and open questions} in our
analysis:


We treated \(z_1, z_0, z_A, h, h_A\) as exogenous. In reality, these
could evolve. For example, \(z_A\) might improve over time as AI
learns from data (as per Wang \& Wong (2025) scenario). Also, human
skills \(z_0, z_1\) could respond to the presence of AI (educational
systems might train people differently if certain tasks are
automated). Incorporating such feedback is an important extension.

We assumed learning \(\lambda\) happens only through mentoring. Could
there be alternative pathways? Perhaps juniors could learn from AI (a
form of AI-driven training). If an AI can codify expert knowledge,
maybe juniors could acquire skills faster on their own. This would
mitigate the dynamic loss. Preliminary evidence (e.g., improved novice
performance with AI tools) gives credence to this possibility.
However, skeptics counter that true expertise often requires rich
tacit knowledge that comes from experience, not just AI advice. More
research (empirical and theoretical) is needed to understand AI's role
as a teacher vs.~as a crutch that {prevents} learning (as seen in
education contexts where students over-rely on AI and don't learn the
material).

Our equilibrium analysis with learning didn't delve into strategic
behavior much (except a brief mention of juniors internalizing
learning). In a dynamic game, one could ask: will seniors
{under-invest in training} juniors or even intentionally not pass
on knowledge to remain valuable (the classic ``knowledge hoarding''
problem)? How might that interact with AI adoption (since an
alternative to hoarding is just not having juniors at all)? These
nuances could be important in assessing whether the market
under-provides learning opportunities.

Finally, there's the question of {policy and welfare}: if we
determined that AI adoption is dynamically inefficient (i.e., society
would be better off in the long run if some juniors were trained),
what is the best way to achieve that? A blunt ban on AI in certain
tasks seems unlikely and inefficient. Incentive-based approaches (like
training subsidies or tax adjustments) are more promising and were
discussed above. One could formally model a social planner or
government that values future productivity and see what the optimal
intervention would be. This intersects with the literature on R\&D
policy and human capital externalities.

To conclude, our model provides a theoretical framework to think about
the {long-term consequences of AI on the labor force's skill
composition}. It suggests that even if AI brings immediate gains, we
should be vigilant about its impact on {career dynamics and
learning}. The full impact of generative AI on the workforce will play
out over decades; by combining insights from models like ours with
empirical monitoring, policymakers and firms can hopefully steer toward
outcomes where AI technologies {augment} human capabilities and
sustain growth, rather than create a short-lived spike in productivity
followed by stagnation due to missing human expertise. The evolving
literature -- from Buera et al.'s work on dynamic competition to
Acemoglu et al.'s calls for human-centric AI deployment -- all point to
a common message: {do not ignore the dynamic effects}. Our
contribution is to highlight the apprenticeship dimension of those
dynamic effects in the age of AI, an area that will surely benefit from
further research and data in the coming years.


\section*{References}\label{references}
\begin{itemize}

\item
  Buera, F. et al.~(2025). {The Life-cycle of Concentrated
  Industries}. (EFG Draft). {[}We refer to dynamic efficiency analysis
  in this paper.{]}
\item
  Heß, P., Janssen, S., \& Leber, U. (2023). {The effect of
  automation technology on workers' training participation}.
  {Economics of Education Review, 96}, 102438. {[}Finds workers
  exposed to automation are significantly less likely to receive
  training.{]}
\item
  Mühlemann, S. (2024). {AI Adoption and Workplace Training}. IZA
  Discussion Paper No.~17367. {[}Shows AI-adopting firms cut training
  for current workers and hire more skilled workers, but also increase
  apprenticeships in SMEs.{]}
\item
  Brynjolfsson, E., Li, D., \& Raymond, L. (2023). {Generative AI
  at Work}. NBER Working Paper 31161 (rev. Nov 2023). {[}Field
  experiment with customer support agents; AI boosted productivity 14\%,
  especially for novice workers, and helped disseminate expert best
  practices.{]}
\item
  Acemoglu, D. (2024). {The Simple Macroeconomics of AI}. (Working
  Paper, April 2024). {[}Argues modest productivity gains from AI and
  that AI could increase capital share; also notes AI can increase
  inequality even if it improves some low-skill productivity.{]}
\item
  Acemoglu, D., Johnson, S., \& others (2023). {Human-Centric AI}
  (CEPR Policy Insight No.~124). {[}Advocates for AI that complements
  workers; discusses policy changes like tax reform to encourage
  hiring/training over pure automation.{]}
\item
  Wang, P., \& Wong, T.N. (2025). {Artificial Intelligence and
  Technological Unemployment}. NBER Working Paper 33867. {[}Model of AI
  as learning-by-using; scenarios of AI initially complementing then
  substituting labor.{]}
\item
  Appelo, J. (2025). ``AI Wrecks the Corporate Career Ladder. Give
  Juniors the Steering Wheel!'' {The Maverick Mapmaker} (Medium,
  Mar 26, 2025). {[}Discusses how firms dropping junior hiring due to AI
  threatens apprenticeship and innovation; provides a practitioner
  perspective.{]}
\end{itemize}
\end{document}